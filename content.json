{"meta":{"title":"麦田麦穗","subtitle":"","description":"","author":"vison","url":"http://visonforcoding.xyz","root":"/"},"pages":[{"title":"所有分类","date":"2020-09-23T07:01:29.446Z","updated":"2020-09-23T07:01:29.446Z","comments":true,"path":"categories/index.html","permalink":"http://visonforcoding.xyz/categories/index.html","excerpt":"","text":""},{"title":"关于","date":"2021-03-31T09:58:40.449Z","updated":"2021-03-31T09:58:40.449Z","comments":true,"path":"about/index.html","permalink":"http://visonforcoding.xyz/about/index.html","excerpt":"","text":"13年，网络工程专业毕业 PHP/JAVA/PYTHON编程开发 wechat: AI348462402 备注：github.io"},{"title":"我的朋友们","date":"2021-06-03T06:39:43.032Z","updated":"2021-06-03T06:39:43.032Z","comments":true,"path":"friends/index.html","permalink":"http://visonforcoding.xyz/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"所有标签","date":"2020-09-23T07:00:24.915Z","updated":"2020-09-23T07:00:24.915Z","comments":true,"path":"tags/index.html","permalink":"http://visonforcoding.xyz/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"关于OKR的思考","slug":"关于OKR的思考","date":"2021-09-06T12:01:29.000Z","updated":"2021-09-07T03:37:30.399Z","comments":true,"path":"2021/09/06/关于OKR的思考/","link":"","permalink":"http://visonforcoding.xyz/2021/09/06/%E5%85%B3%E4%BA%8EOKR%E7%9A%84%E6%80%9D%E8%80%83/","excerpt":"起因是由于我的老板在月初的时候又布置任务要求写下本月的关键目标Top3。也就是OKR Top3,并且要求用SMART原则。 在此之前领导一直告诉我们KPI和OKR是分别用来管理销售团队和职能团队的。因为销售团队很容易用数据指标来衡量工作结果，但职能团队的工作并不好用数据指标来衡量。 但是SMART原则五条又有Measurable(可衡量的),于是我有点惊讶。如果OKR+SMART那跟KPI有什么区别？","text":"起因是由于我的老板在月初的时候又布置任务要求写下本月的关键目标Top3。也就是OKR Top3,并且要求用SMART原则。 在此之前领导一直告诉我们KPI和OKR是分别用来管理销售团队和职能团队的。因为销售团队很容易用数据指标来衡量工作结果，但职能团队的工作并不好用数据指标来衡量。 但是SMART原则五条又有Measurable(可衡量的),于是我有点惊讶。如果OKR+SMART那跟KPI有什么区别？ 于是我认为OKR+SMART = KPI. 但究竟是不是这样呢？ OKR和KPI先来看看KPI，因为本身OKR是后来才提出来的概念。相较于OKR，KPI更广和更早被人所知。 KPI 是 Key Performance Indicator 的缩写，中文名称是「关键绩效指标」，即一系列衡量工作成效的重要指标。 关键点有了，指标 KPI 必须是客观的、可衡量的，以下是一些常见的 KPI： 医疗保健行业：患者等待时间、平均治疗费用 零售行业：坪效、每名员工销售额 人力资源部门：离职率、平均招聘时间 销售部门：销售收入、拨打电话的次数 客服部门： 客户满意度NPS 再来看下OKR OKR 是 Objective and Key Results 的缩写，中文名称是「目标与关键结果法」，是一套帮助组织实现目标管理、推动执行与协作的工具和方法，关键点工具和方法。 当然KPI也可以理解为方法，但是OKR的工具性和方法指导意义会更强。 OKRoKR强调在”第一性原理”思考方式的基础上,聚焦战略重点,提岀鼓舞人心的目标,选择RO更优的策略,从而激发组织活力,降低共识成本,促进团队和个人围绕组织目标高效协作. 一个公司都会指定公司终生奋斗的使命，愿景。 关于使命和愿景 我也听到过我领导跟我讲的比较有意思的解释版本。 使命 可能是当下就可以实现的。愿景 可能不能实现，但是公司要为之奋斗的目标。 例如 apple 愿景：让每人拥有一台计算机；使命：推广公平的资料使用惯例，建立用户对互联网之信任和信心 言归正传。为了完成使命或者接近愿景。公司高层必然会制定长期的战略计划。 那么为了这些战略计划，每个层级每个人都因为想到我可以完成什么和如何达到目标。 以及更细化的为了落地这些目标和关键结果 需要建立哪些项目或项目任务 从宏观的企业战略到微观个人任务，OKR能很好的成为企业目标管理体系和个人的工作方法。 OKR是更符合时代需要的管理方法 企业端:VUCA时代,让组织持续进化是应对不确定性的根本 人才端:个体崛起,管理从强调管控走冋自驱与协作 普适性:围绕目标开展工作是很自然的事 供给端: OKR SaaS把领先实践产品化,让更多企业以低成本受益 认知:OKR不是万能药,正确认识OKR才能用好OKR 战略层面:从长远规划转向敏捷迭代 过去企业做战略通常要看3-5年,前提是市场允许你保持线性增长的合理预期。今天,非线性增长成为普遍情况,企业更加聚焦在眼前的半年或一年,以更快的速度应对市场和需求变化。 组织层面:从科层制、条线式运作,向分布式决策、网络化协作的方向发展 科层制最大的特点,是指令式的上传下达,每一层都依赖上一层的决策,较为被动低效,也难以产生创新。分布式、网络化的组织里,每个节点(团队或个人)都更加自主的决策和行动,主动发起协作,更及时的响应变化,涌现更多创新。 文化层面:从强调管控、一致到更加多元化、兼容并蓄 强调管控也是科层制组织特征的延续,今天的组织需要更多样化的思想和实践,产生新的变化,在內外部形成更加健康的生态,才能产生更多可能性。 OKR让每一位员工了解组织的整体目标,找到自己工作与组织目标的联系,获得意义与成就感 OKR认知第一,OKR并不解决战略规划的问题 ○KR能够帮助企业更好地思考和落地战略,但不是用了OKR就有更好的战略OKR本质是一种人人皆围绕战略在主动思考并度量结果的方法和工具 第二,OKR不能代替领导力 仅仅设定一个目标并不能带来成功,领导者、管理者带领团队共同努力,才能更好达成目标各级管理者都必须主动思考业务本质和最佳路径通过OKR分派任务,是对OKR的误用,更是管理上的懒政 第三,OKR不是绩效考核 目标管理让员工专注思考如何实现目标,绩效考核专注于对员工所做贡献给予公平回报,前者是价值创造,后者是价值分配,二者有本质区别领先实践主张将目标管理和绩效评价解绑。例如谷歌、字节跳动,○KR作为目标管理工具,绩效考核通过360°评价实现。如果直接考核OKR达成率,组织势必又将陷入KP|式的讨价还价,也更容易滋生短期行为 OKR落地 OKR的实施步骤遵循经典的“PDCA”目标管理流程。以年度为例,○KR的运行一般遵循 目标制定-过程跟进-总结复盘-考核应用四步实施流程,并形成闭环管理。 在一个年度内,会有多个双月或季度OKR周期,此周期内主要以目标制定-过程跟进-总结复盘环节形成的小闭环进行运作。 五大成功因素 高层管理者的积极参与 把OKR应用到日常管理 创造良好的实施环境 便捷高效的OKR系统 专门的OKR运营团队 这里 我认为 第一 第二点尤为重要。 总结 OKR不同于KPI，OKR+SMART 也不等于KPI OKR是更适应当代的管理工具，面对新时代的”人”和瞬即万变的快节奏 并不意味着可以摈弃KPI，而应采取OKR为主KPI为辅的方式。 对KPI的认知尤为重要，上到最高层下到基层都应该理解OKR的作用和如何运用OKR。 所有管理方法都应以人为本，离不开基础的沟通、演讲技巧。要让方法发挥功效，还需要有强大的感召力。","categories":[],"tags":[{"name":"管理","slug":"管理","permalink":"http://visonforcoding.xyz/tags/%E7%AE%A1%E7%90%86/"}]},{"title":"代码整洁之道","slug":"代码整洁之道","date":"2021-07-30T01:42:27.000Z","updated":"2021-07-30T01:43:13.299Z","comments":true,"path":"2021/07/30/代码整洁之道/","link":"","permalink":"http://visonforcoding.xyz/2021/07/30/%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93/","excerpt":"软件质量不但依赖于架构及项目管理，还与代码质量紧密相关。 代码质量与整洁度成正比，干净的代码即在质量上较为可靠，也为后期维护、升级奠定良好基础。 另一种概念叫做极限编程 童子军军规让营地比你来时更干净","text":"软件质量不但依赖于架构及项目管理，还与代码质量紧密相关。 代码质量与整洁度成正比，干净的代码即在质量上较为可靠，也为后期维护、升级奠定良好基础。 另一种概念叫做极限编程 童子军军规让营地比你来时更干净 有意义的命名 名副其实，表达真实意义 不误导 做有意义的区分，避免 a、b、c 可读、可搜索 函数 单一职责 行数 20-100 函数参数 0参数最佳，3个参数已经勉为其难 标识参数丑陋不堪，向参数传入布尔值骇人听闻 如果函数需要三个以上的参数，说明这些参数应该封装为类了 Circle makeCircle(double x,double y,double radius); Circle makeCircle(Point center,double radius); class Foo &#123; public function bar($flag = true) &#123; &#125; 无副作用函数承诺只做一件事，实际上还做了其他的。 public class UserValidator &#123; private Cryptographer cryptographer; public boolean checkPassword(String userName, String password)&#123; User user = UserGateway.findByName(userName) ; if (user != User.NULL) &#123; String codedPhrase = user.getPhraseEncodedByPassword(); String phrase = cryptographer.decrypt (codedPhrase,password ); if(&quot;Valid Password&quot;.equals(phrase))&#123; Session.initialize(); //实际上还做了session 初始化的操作 return true; &#125; return false; &#125; 要么抽离Session.initialize(),要么重命名为checkPasswordAndInitializeSession 不要给人误导。 使用异常代替错误码使用错误码就要定义错误码枚举，枚举类被大量导入调用。一旦增加或修改错误枚举，就要对所有引入的文件进行编译。 if (deletePage(page)==E_OK)&#123; if (registry.deleteReference(page.name)==E_OK)&#123; if (configKeys.deleteKey(page.name.makeKey())==E_OK)&#123; logger.log(&quot;page deleted&quot;); &#125; else &#123; logger.log(&quot;configKey not deleted&quot;); &#125; else &#123; logger. log(&quot;deleteReference from registry failed&quot;); &#125; else &#123; logger.log(&quot;delete failed&quot;); &#125; return E_ERROR; &#125; try &#123; deletePage(page); registry.deleteReference(page.name); configKeys.deleteKey(page.name.makeKey()); &#125; catch (Exception e) &#123; logger.log(e.getMessage()); &#125; 注释注释并不像辛德勒的名单。它们并不“纯然地好”。实际上，注释最多也就是一种必须的恶。若编程语言足够有表达力，或者我们长于用这些语言来表达意图，就不那么需要注释——也许根本不需要。 注释掉的代码20世纪60年代，曾经有那么一段时间，注释掉的代码可能有用。但我们已经拥有优良的源代码控制系统如此之久，这些系统可以为我们记住不要的代码。我们无需再用注释来标记，删掉即可，它们丢不了。我担保。 格式文件长度 200-500 行字符数 上限120 对象和数据结构德莫特定律著名的得墨式耳律（The Law of Demeter)认为，模块不应了解它所操作对象的内部形。如上节所见，对象隐藏数据，曝露操作。这意味着对象不应通过存取器曝露其内部结构因为这样更像是曝露而非隐藏其内部结构。更准确地说，得墨式耳律认为，类C的方法f只应该调用以下对象的方法： C 由f创建的对象； 作为参数传递给f的对象； 由C的实体变量持有的对象。 null 别传null值 别返回null值 系统“复杂要人命。它消磨开发者的生命，让产品难以规划、构建和测试。”——Ray Ozzie,微软公司首席技术官 依赖注入在依赖管理情景中，对象不应负责实体化对自身的依赖。反之，它应当将这份权责移交给其他“有权力”的机制，从而实现控制的反转。因为初始设置是一种全局问题，这种授权机制通常要么是main例程，要么是有特定目的的容器。 扩容 “一开始就做对系统”纯属神话。 代理AOP有时会与实现它的技术相混淆，例如方法拦截和通过代理做的“封包”。AOP系统的真正价值在于用简洁和模块化的方式指定系统行为。 并发编程并发编程很难，非常难。如果你不那么细心，就会搞出不堪入目的东西来。看看以下常见的迷思和误解： 并发总能改进性能并发有时能改进性能，但只在多个线程或处理器之间能分享大量等待时间的时候管用。事情没那么简单。 编写并发程序无需修改设计事实上，并发算法的设计有可能与单线程系统的设计极不相同。目的与时机的解藕往往对系统结构产生巨大影响。 在采用Web或EJB容器的时候，理解并发问题并不重要实际上，你最好了解容器在做什么，了解如何对付本章后文将提到的并发更新、死锁等问题。 下面是一些有关编写并发软件的中肯说法： 并发会在性能和编写额外代码上增加一些开销； 正确的并发是复杂的，即便对于简单的问题也是如此；并发缺陷并非总能重现，所以常被看做偶发事件而忽略，未被当做真的缺陷看待； 并发常常需要对设计策略的根本性修改。 味道建议命名常量代替魔术数准确 用浮点数表示货币几近于犯罪。 因为你不想做并发更新就避免使用锁和/或事务管理往好处说也是一种懒惰行为。在代码中做决定时，确认自己足够准确。 明确自己为何要这么做，如果遇到异常情况如何处理。 别懒得理会决定的准确性。如果你打算调用可能返回null的函数，确认自己检查了null值。 如果查询你认为是数据库中唯一的记录，确保代码检查不存在其他记录。 如果要处理货币数据，使用整数！并恰当地处理四舍五入。 如果可能有并发更新，确认你实现了某种锁定机制。 代码中的含糊和不准确要么是意见不同的结果，要么源于懒惰。无论原因是什么，都要消除。 返回异常 /** * * @param array $awbnos * @throws Exception|ConnectionTimeOutException * @return array Description */ public function fetchTrace(array $awbnos):array &#123; &#125; php 利用 phpdoc 和 php7 特性能支持让调用者注意异常和返回值的正确处理。 public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception&#123; &#125; java 函数定义语法天生支持。 避免过多嵌套 基本法 单一职责，贯彻落实 短、少，类1000行，方法120行，参数3个，严格要求。 消灭mess,有1个就会有无数个 Later equals never 稍后等于永不，别等现在就去做 打磨，分解函数、修改名称、消除重复。缩短和重新安置方法。有拆散类。同时保持测试通过。保持重构、热爱重构、注意单元测试回归测试 推荐阅读 《Clean Code》 http://kaelzhang81.github.io/2020/04/10/译-设计高质量软件/","categories":[],"tags":[{"name":"技术工程","slug":"技术工程","permalink":"http://visonforcoding.xyz/tags/%E6%8A%80%E6%9C%AF%E5%B7%A5%E7%A8%8B/"}]},{"title":"利用PHPMD让你的php代码更干净更易维护","slug":"php/利用PHPMD让你的php代码更干净更易维护","date":"2021-07-27T06:01:44.000Z","updated":"2021-08-23T08:57:29.119Z","comments":true,"path":"2021/07/27/php/利用PHPMD让你的php代码更干净更易维护/","link":"","permalink":"http://visonforcoding.xyz/2021/07/27/php/%E5%88%A9%E7%94%A8PHPMD%E8%AE%A9%E4%BD%A0%E7%9A%84php%E4%BB%A3%E7%A0%81%E6%9B%B4%E5%B9%B2%E5%87%80%E6%9B%B4%E6%98%93%E7%BB%B4%E6%8A%A4/","excerpt":"PHPMD - PHP Mess Detector 等价于java工具PMD，能够对php 源代码进行如下问题检测： 可能的bug 欠佳的代码 过于复杂的表达式 未使用的方法、变量、参数、属性 最新版本发布于 2021/05/11","text":"PHPMD - PHP Mess Detector 等价于java工具PMD，能够对php 源代码进行如下问题检测： 可能的bug 欠佳的代码 过于复杂的表达式 未使用的方法、变量、参数、属性 最新版本发布于 2021/05/11 https://phpmd.org/about.html 基本使用phpmd /path/to/source text codesize 第一个参数 要检测的代码地址 第二个参数指定输出检测结果的格式 第三个参数是指定的规则集 规则集合 Clean Code: 一些包含clean code的规则集合，包括面向对象设计的 SOLID（单一功能、开闭原则、里氏替换、接口隔离以及依赖反转）原则。 Code Size : 有关代码大小的相关问题，例如行数等 Controversial : 具有争议的规则，可以不参考此规则 Design ： 设计规则，包含类依赖数量等等 Naming: 命名规则 Unused Code: 未使用代码规则 关于clean code 有一本书名就叫 &lt;&lt; Clean Code &gt;&gt;,个人读下来感受颇深。 这里主要介绍一些我认为非常有必要注意的规则 Clean CodeBooleanArgumentFlag布尔标志参数违反单一责任原则（SRP）,可以将此类方法一拆为二。 class Foo &#123; public function drink($thirsty = true) &#123; if($thirsty)&#123; // 喝2杯 &#125;else&#123; // 喝一杯 &#125; &#125; &#125; class Foo &#123; public function drinkThirsty() &#123; // 喝2杯 &#125; public function drinkUnThirsty() &#123; // 喝2杯 &#125; &#125; ElseExpressionclass Foo &#123; public function bar($flag) &#123; if ($flag) &#123; // one branch &#125; else &#123; // another branch &#125; &#125; &#125; 像这样的if else的表达式其实是没必要的，可通过三元表达式、拆分方法或者可能的情况下先return来规避这类问题，以将代码简单或增加可读性。 class Foo &#123; public function bar($flag) &#123; if ($flag) &#123; // one branch return &#125; // another branch &#125; &#125; Code SizeCyclomaticComplexity圈复杂度，用来衡量代码复杂度的一个计算规则。复杂度越高代表代码可读性、可维护性越差，易错性更高、集成测试更难。 点边计算法 上述表达式的圈复杂度为 e = 10 n = 8 Cyclomatic Complexity = 10 - 8 + 2 = 4 计算公式为： V(G) = E - N + 2 其中，e表示控制流图中边的数量，n表示控制流图中节点的数量。 更多可参考 http://kaelzhang81.github.io/2017/06/18/详解圈复杂度/ ExcessiveMethodLength方法长度，该规则有2个属性 minimum 最小限定值 默认 100 ignore-whitespace 是否忽略空白行 默认 false ExcessiveClassLength类长度 minimum 最小限定值 默认 1000 ignore-whitespace 是否忽略空白行 默认 false ExcessiveParameterList参数个数限定 minimum 10，根据《clean code》一书的说法，这个值应该限定为3 ExcessivePublicCount公共方法、公共属性 minimum 45 TooManyFieldsmaxfields 15 TooManyMethodsmaxmethods 25ignorepattern (^(set|get))i TooManyPublicMethodsmaxmethods 10 The method count reporting thresholdignorepattern (^(set|get))i 自定义规则有的默认规则也许并不能满足自身需求需做舍弃或修改。例如函数参数数，在《clean code》一书中定义的是最多为3，而phpmd默认指定的是10. 10个确实已经非常难看了，想象你去调用一个有10个参数的函数，你一定会吐槽懵逼的。 好在phpmd这些都可以修改，如下： 引入unusedcode规则集 引入codesize,并暂时排除NPathComplexity和CyclomaticComplexity这两个理解起来有一定困难的规则。诚然CyclomaticComplexity在度量复杂度十分有效，但若你的所有函数已经满足ExcessiveMethodLength已经进步很大了，所以一步步来。 修改ExcessiveParameterList,让限定值为3. 修改ExcessiveMethodLength和ExcessiveClassLength,忽略空白行 排除StaticAccess规则 &lt;?xml version=&quot;1.0&quot;?&gt; &lt;ruleset name=&quot;My first PHPMD rule set&quot; xmlns=&quot;http://pmd.sf.net/ruleset/1.0.0&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://pmd.sf.net/ruleset/1.0.0 http://pmd.sf.net/ruleset_xml_schema.xsd&quot; xsi:noNamespaceSchemaLocation=&quot; http://pmd.sf.net/ruleset_xml_schema.xsd&quot;&gt; &lt;description&gt; My custom rule set that checks my code... &lt;/description&gt; &lt;rule ref=&quot;rulesets/unusedcode.xml&quot; /&gt; &lt;rule ref=&quot;rulesets/codesize.xml&quot;&gt; &lt;exclude name=&quot;ExcessiveParameterList&quot; /&gt; &lt;exclude name=&quot;NPathComplexity&quot;/&gt; &lt;exclude name=&quot;CyclomaticComplexity&quot;/&gt; &lt;/rule&gt; &lt;rule ref=&quot;rulesets/codesize.xml/ExcessiveParameterList&quot;&gt; &lt;properties&gt; &lt;property name=&quot;minimum&quot;&gt; &lt;value&gt; 3 &lt;/value&gt; &lt;/property&gt; &lt;/properties&gt; &lt;/rule&gt; &lt;rule ref=&quot;rulesets/codesize.xml/ExcessiveClassLength&quot;&gt; &lt;properties&gt; &lt;property name=&quot;ignore-whitespace&quot;&gt; &lt;value&gt; true &lt;/value&gt; &lt;/property&gt; &lt;/properties&gt; &lt;/rule&gt; &lt;rule ref=&quot;rulesets/codesize.xml/ExcessiveMethodLength&quot;&gt; &lt;properties&gt; &lt;property name=&quot;ignore-whitespace&quot;&gt; &lt;value&gt; true &lt;/value&gt; &lt;/property&gt; &lt;/properties&gt; &lt;/rule&gt; &lt;rule ref=&quot;rulesets/cleancode.xml&quot;&gt; &lt;exclude name=&quot;StaticAccess&quot; /&gt; &lt;/rule&gt; &lt;/ruleset&gt;","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://visonforcoding.xyz/tags/PHP/"}]},{"title":"用phpunit进行单元测试","slug":"php/用phpunit进行单元测试","date":"2021-07-23T01:48:24.000Z","updated":"2021-08-23T08:57:33.913Z","comments":true,"path":"2021/07/23/php/用phpunit进行单元测试/","link":"","permalink":"http://visonforcoding.xyz/2021/07/23/php/%E7%94%A8phpunit%E8%BF%9B%E8%A1%8C%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/","excerpt":"最近读了一本书《clean code》。深有感悟，感觉非常接底气，讲到了日常编码中真正遇到的困扰。大致我总结下就是要做几件事： 重构，定期重构，保持重构 clean code,编写整洁、易维护的代码 单元测试 本篇我们讲下如何利用phpunit进行单元测试","text":"最近读了一本书《clean code》。深有感悟，感觉非常接底气，讲到了日常编码中真正遇到的困扰。大致我总结下就是要做几件事： 重构，定期重构，保持重构 clean code,编写整洁、易维护的代码 单元测试 本篇我们讲下如何利用phpunit进行单元测试 安装这里主要说明下安装的版本问题，最新版phpunit-latest目前依赖php7.4. 但是我们线上版本仍然是php7.2,因此我们需要安装旧的版本. https://phpunit.de/announcements/phpunit-8.html 从这个链接能找到phpunit-8。 安装的方式有2种，PHAR 和 composer，两种方式都可以全局安装。 https://phpunit.readthedocs.io/zh_CN/latest/installation.html#installation-requirements 官方的教程文档里不推荐进行全局安装。 请注意，并不推荐全局安装 PHPUnit，比如说放在 /usr/bin/phpunit 或 /usr/local/bin/phpunit。相反，PHPUnit 应该作为项目本地依赖项进行管理。 但是我还是选择全局安装，因为不想将本地太多依赖。 使用IDE提示&lt;?php declare(strict_types=1); use PHPUnit\\Framework\\TestCase; final class RedisCacheTest extends TestCase &#123; public function testSet(): void &#123; $res = \\Hll\\Cache\\Cache::set(&#39;foo&#39;, date(&#39;Y-m-d H:i:s&#39;),10); $this-&gt;assertTrue($res); &#125; &#125; 这是我的一个测试用例脚本，测试脚本类需要继承TestCase. 由于我的安装方式并不是本地项目安装，所以在ide不会提示TestCase的相关方法。这对于来说是不能容忍的，不过好在IDE能额外的配置引入项目外的文件进行提示。 工程目录再来看看工程目录结构 在我编写的一个cache组件库中 src作为源代码目录 tests作为测试用例目录 bootstrap.php是phpunit的启动加载文件，用于做些全局的初始化动作，比如加载autoload. 执行测试phpunit --bootstrap tests/bootstrap.php --verbose tests/case 该命令是执行测试 tests/case下的所有测试用例文件，当然你也可以具体到只执行单个文件。 --bootstrap 加载启动文件 --colors 彩色输出 --debug 输出调试信息，例如当一个测试开始执行时输出其名称。 --testtox 以testtox格式显示测试结果 --configuration、-c 从 XML 文件中读取配置信息。 如果phpunit.xml 或 phpunit.xml.dist（按此顺序）存在于当前工作目录并且未使用 --configuration，将自动从此文件中读取配置。","categories":[],"tags":[{"name":"php","slug":"php","permalink":"http://visonforcoding.xyz/tags/php/"}]},{"title":"学习编写php拓展","slug":"php/学习编写php拓展","date":"2021-07-07T07:10:27.000Z","updated":"2021-07-07T07:10:59.919Z","comments":true,"path":"2021/07/07/php/学习编写php拓展/","link":"","permalink":"http://visonforcoding.xyz/2021/07/07/php/%E5%AD%A6%E4%B9%A0%E7%BC%96%E5%86%99php%E6%8B%93%E5%B1%95/","excerpt":"","text":"目的为什么要学习编写php拓展？ 1.目前市面上有数据库或中间件无php驱动2.有自己的公共组件或函数,虽然可以使用composer，为了提升性能替代composer包3.为了学习php内核原理或其他拓展的内部实现原理 hello,world1.源码下载 wget https://www.php.net/distributions/php-7.2.19.tar.bz2 tar -xvf php-7.2.19.tar.bz2 2.增加函数声明 vim php_vison.h # 在其中增加 PHP_FUNCTION(vison_print); vim vison.c # 将如下代码中的PHP_FE和PHP_FE_END中加入下面代码（这的代码是将函数指针注册到Zend引擎） PHP_FE(vison_print, NULL) 3.函数定义 vim vison.c 在最后加上创建执行方法vison_print PHP_FUNCTION(vison_print) &#123; php_printf(&quot;Hello vison!\\n&quot;); RETURN_TRUE; &#125; 4.编译 phpize ./configure &amp;&amp; make &amp;&amp; make install # 然后将生成的vison.so放入配置 vim /etc/php.ini extension=vison.so #然后输入php -m查看配置 4.验证 php -r &quot;vison_print();&quot;","categories":[],"tags":[{"name":"php","slug":"php","permalink":"http://visonforcoding.xyz/tags/php/"}]},{"title":"RabbitMQ介绍和场景使用","slug":"RabbitMQ介绍和场景使用","date":"2021-06-25T01:28:32.000Z","updated":"2021-06-25T01:29:55.159Z","comments":true,"path":"2021/06/25/RabbitMQ介绍和场景使用/","link":"","permalink":"http://visonforcoding.xyz/2021/06/25/RabbitMQ%E4%BB%8B%E7%BB%8D%E5%92%8C%E5%9C%BA%E6%99%AF%E4%BD%BF%E7%94%A8/","excerpt":"安装version: &#39;3.1&#39; services: rabbitmq-manger: image: rabbitmq:3-management restart: always ports: - 5672:5672 - 8091:15672 使用docker进行快速安装 历史 2007年8月，Rabbit公司发行了 RabbitMQ 1.1.0. 2009年8月，VMware出资4.2亿美元收购了SpringSource[9]，并在一段时间内作为VMware的一个独立的部门；公司原有的商业产品以vFabric应用套件名义发售。之后SpringSource又接连收购了RabbitMQ[10]、Redis[11]和Gemstone[12]。除Redis外，它们的产品也成为了vFabric应用套件的一部分。 你会发现一个有趣而诧异的事实，VMware 和 Spring 、RabbitMQ、Redis这些大名鼎鼎的技术是同属一家公司。而 著名的 Spring背后的SpringSource公司主要以培训和咨询盈利。","text":"安装version: &#39;3.1&#39; services: rabbitmq-manger: image: rabbitmq:3-management restart: always ports: - 5672:5672 - 8091:15672 使用docker进行快速安装 历史 2007年8月，Rabbit公司发行了 RabbitMQ 1.1.0. 2009年8月，VMware出资4.2亿美元收购了SpringSource[9]，并在一段时间内作为VMware的一个独立的部门；公司原有的商业产品以vFabric应用套件名义发售。之后SpringSource又接连收购了RabbitMQ[10]、Redis[11]和Gemstone[12]。除Redis外，它们的产品也成为了vFabric应用套件的一部分。 你会发现一个有趣而诧异的事实，VMware 和 Spring 、RabbitMQ、Redis这些大名鼎鼎的技术是同属一家公司。而 著名的 Spring背后的SpringSource公司主要以培训和咨询盈利。 概念 RabbitMQ is a message broker: it accepts and forwards messages. You can think about it as a post office: when you put the mail that you want posting in a post box, you can be sure that Mr. or Ms. Mailperson will eventually deliver the mail to your recipient. In this analogy, RabbitMQ is a post box, a post office and a postman. 这是官网最开头的一段介绍,这里将RabbitMQ类比为邮局派信场景，RabbitMQ扮演邮箱、邮局、邮差的角色。这里也看到了 broker 这个单词，Kafka也有broker这个概念，这里我们暂且将它理解为代理的意思。 生产者 producer简单理解就是发送消息的程序 消费者 consumer 队列 queue 消息存储于queue当中，多个producer 可往一个 queue发送消息 交换机 Exchange 交换机是用来发送消息的AMQP实体。交换机拿到一个消息之后将它路由给一个或零个队列。它使用哪种路由算法是由交换机类型和被称作绑定（bindings）的规则所决定的(这个后面会讲到)。 Exchange Type direct 直连 fanout 扇出 topic 主题 headers 头 除交换机类型外，在声明交换机时还可以附带许多其他的属性，其中最重要的几个分别是： Name Durability （消息代理重启后，交换机是否还存在） Auto-delete （当所有与之绑定的消息队列都完成了对此交换机的使用后，删掉它） Arguments（依赖代理本身） public function exchange_declare( $exchange, $type, $passive = false, $durable = false, $auto_delete = true, $internal = false, $nowait = false, $arguments = array(), $ticket = null ) 持久（durable）、暂存（transient）。持久化的交换机会在消息代理（broker）重启后依旧存在，而暂存的交换机则不会（它们需要在代理再次上线后重新被声明）。然而并不是所有的应用场景都需要持久化的交换机。 默认交换机 那就是每个新建队列（queue）都会自动绑定到默认交换机上，绑定的路由键（routing key）名称与队列名称相同。 直连交换机 Direct $channel-&gt;queue_bind(&#39;hello_queue&#39;, &#39;hello_exchange&#39;, &#39;hello_key&#39;); 它是如何工作的： 将一个队列绑定到某个交换机上，同时赋予该绑定一个路由键（routing key） 当一个携带着路由键为hello_key的消息被发送给直连交换机hello_exchange时，交换机会把它路由给hello_queue的队列。 $channel-&gt;basic_publish($msg, &#39;hello_exchange&#39;, &#39;hello_key&#39;); 扇形交换机 fanout 扇型交换机（funout exchange）将消息路由给绑定到它身上的所有队列，而不理会绑定的路由键。 如果N个队列绑定到某个扇型交换机上，当有消息发送给此扇型交换机时，交换机会将消息的拷贝分别发送给这所有的N个队列。 // RabbitFanoutProduce.php $faker = Factory::create(&#39;zh_CN&#39;); $connection = new AMQPStreamConnection(&#39;192.168.106.179&#39;, 5672, &#39;guest&#39;, &#39;guest&#39;); // 创建通道 $channel = $connection-&gt;channel(); $channel-&gt;exchange_declare(&#39;test.fanout&#39;, AMQPExchangeType::FANOUT, false, false, false); $body = $faker-&gt;text(20); $msg = new AMQPMessage($body, [&#39;delivery_mode&#39; =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT]); $channel-&gt;basic_publish($msg, &#39;test.fanout&#39;); RabbitFanoutProduce 生产者定义了一个test.fanout 交换机类型是AMQPExchangeType::FANOUT // lmsConsoumer.php $connection = new AMQPStreamConnection(&#39;192.168.106.179&#39;, 5672, &#39;guest&#39;, &#39;guest&#39;); // 创建通道 $channel = $connection-&gt;channel(); $channel-&gt;queue_declare(&#39;test.lms&#39;, false, false, false); $channel-&gt;queue_bind(&#39;test.lms&#39;, &#39;test.fanout&#39;); $callback = function ($msg) &#123; echo &#39; [x] &#39;, $msg-&gt;body, &quot;\\n&quot;; &#125;; $channel-&gt;basic_consume(&#39;test.lms&#39;, &#39;&#39;, false, true, false, false, $callback); while ($channel-&gt;is_open()) &#123; $channel-&gt;wait(); &#125; lmsConsoumer 订阅了一个test.lms的队列并绑定到test.fanout交换机 // omsConsoumer.php $connection = new AMQPStreamConnection(&#39;192.168.106.179&#39;, 5672, &#39;guest&#39;, &#39;guest&#39;); // 创建通道 $channel = $connection-&gt;channel(); $channel-&gt;queue_declare(&#39;test.oms&#39;, false, false, false,false); $channel-&gt;queue_bind(&#39;test.oms&#39;, &#39;test.fanout&#39;); $callback = function ($msg) &#123; echo &#39; [x] &#39;, $msg-&gt;body, &quot;\\n&quot;; &#125;; $channel-&gt;basic_consume(&#39;test.oms&#39;, &#39;&#39;, false, true, false, false, $callback); while ($channel-&gt;is_open()) &#123; $channel-&gt;wait(); &#125; omsConsoumer 订阅了一个test.oms的队列并绑定到test.fanout交换机 示例中演示了，一个生产者生产消息给2个系统订阅消费。 Fanout 典型的一个应用场景是多个应用系统订阅一个消息事件。 eg： 客服系统、运营系统、财务系统同时订阅订单系统的订单状态变更事件。 这样不同系统都能各自使用各自的队列处理订单的变更业务逻辑。 细化下场景举个例子： 当订单完结 order close: 客服系统需要给客户发送一个客户满意度调查 运营系统需要发送一张按订单消费金额配比的优惠券 财务系统需要计算这笔订单的入账 主题交换机 topic 主题交换机（topic exchanges）通过对消息的路由键和队列到交换机的绑定模式之间的匹配，将消息路由给一个或多个队列。 topic有点类似 direct和fanout的结合体，即可以广播又可以按一定规则指定 route. 上面示例图案例： 这是一个关于动物的消息消费程序 有关orange的动物将进入Q1 ，例如 fast.orange.pig 快速的橙色猪 有关 rabbit 和 lazy 的动物将进入 Q2 ，例如 lazy.green.rabbit 或 lazy.yellow.monkey 如果匹配多个模式则进入多个相应的队列，例如 lazy.orange.monkey 则会进入Q1和Q2 $faker = Factory::create(&#39;zh_CN&#39;); $connection = new AMQPStreamConnection(&#39;192.168.106.179&#39;, 5672, &#39;guest&#39;, &#39;guest&#39;); // 创建通道 $channel = $connection-&gt;channel(); $channel-&gt;exchange_declare(&#39;test.topic&#39;, AMQPExchangeType::TOPIC, false, false, false); $channel-&gt;queue_declare(&#39;Q1&#39;); $channel-&gt;queue_declare(&#39;Q2&#39;); $channel-&gt;queue_bind(&#39;Q1&#39;, &#39;test.topic&#39;, &#39;*.orange.*&#39;); $channel-&gt;queue_bind(&#39;Q2&#39;, &#39;test.topic&#39;, &#39;*.*.rabbit&#39;); $channel-&gt;queue_bind(&#39;Q2&#39;, &#39;test.topic&#39;, &#39;lazy.#&#39;); $body = $faker-&gt;name(); $msg = new AMQPMessage($body, [&#39;delivery_mode&#39; =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT]); $channel-&gt;basic_publish($msg, &#39;test.topic&#39;, &#39;fast.orange.pig&#39;); $channel-&gt;basic_publish($msg, &#39;test.topic&#39;, &#39;lazy.green.rabbit&#39;); $channel-&gt;basic_publish($msg, &#39;test.topic&#39;, &#39;lazy.orange.monkey&#39;); 可以看到3个消息，发送到了2个队列。Q1和Q2各有2个，因为lazy.orange.monkey进入了2个队列。 头交换机 header 有时消息的路由操作会涉及到多个属性，此时使用消息头就比用路由键更容易表达，头交换机（headers exchange）就是为此而生的。头交换机使用多个消息属性来代替路由键建立路由规则。通过判断消息头的值能否与指定的绑定相匹配来确立路由规则。 它提供更多的匹配，可设置x-match 为any 或all 来控制是任意匹配还是全部匹配。 队列 queueAMQP中的队列（queue）跟其他消息队列或任务队列中的队列是很相似的：它们存储着即将被应用消费掉的消息。队列跟交换机共享某些属性，但是队列也有一些另外的属性。 Name Durable（消息代理重启后，队列依旧存在） Exclusive（只被一个连接（connection）使用，而且当连接关闭后队列即被删除） Auto-delete（当最后一个消费者退订后即被删除） Arguments（一些消息代理用他来完成类似与TTL的某些额外功能） 消息确认消费者应用（Consumer applications） - 用来接受和处理消息的应用 - 在处理消息的时候偶尔会失败或者有时会直接崩溃掉。而且网络原因也有可能引起各种问题。这就给我们出了个难题，AMQP代理在什么时候删除消息才是正确的？AMQP 0-9-1 规范给我们两种建议： 当消息代理（broker）将消息发送给应用后立即删除。（使用AMQP方法：basic.deliver或basic.get-ok） 待应用（application）发送一个确认回执（acknowledgement）后再删除消息。（使用AMQP方法：basic.ack） 前者被称作自动确认模式（automatic acknowledgement model），后者被称作显式确认模式（explicit acknowledgement model)。 $callback = function ($msg) &#123; echo &#39; [x] Received &#39;, $msg-&gt;body, &quot;\\n&quot;; sleep(substr_count($msg-&gt;body, &#39;.&#39;)); echo &quot; [x] Done\\n&quot;; $msg-&gt;ack(); &#125;; $channel-&gt;basic_consume(&#39;task_queue&#39;, &#39;&#39;, false, false, false, false, $callback); 以上代码示例展示ack使用，basic_consume的第4个参数要 设置为true。 拒绝消息当一个消费者接收到某条消息后，处理过程有可能成功，有可能失败。应用可以向消息代理表明，本条消息由于“拒绝消息（Rejecting Messages）”的原因处理失败了（或者未能在此时完成）。当拒绝某条消息时，应用可以告诉消息代理如何处理这条消息——销毁它或者重新放入队列。当此队列只有一个消费者时，请确认不要由于拒绝消息并且选择了重新放入队列的行为而引起消息在同一个消费者身上无限循环的情况发生。 连接AMQP连接通常是长连接。AMQP是一个使用TCP提供可靠投递的应用层协议。AMQP使用认证机制并且提供TLS（SSL）保护。当一个应用不再需要连接到AMQP代理的时候，需要优雅的释放掉AMQP连接，而不是直接将TCP连接关闭。 虚拟主机 vhost为了在一个单独的代理上实现多个隔离的环境（用户、用户组、交换机、队列 等），AMQP提供了一个虚拟主机（virtual hosts - vhosts）的概念。这跟Web servers虚拟主机概念非常相似，这为AMQP实体提供了完全隔离的环境。 $connection = new AMQPStreamConnection(&#39;192.168.106.179&#39;, 5672, &#39;guest&#39;, &#39;guest&#39;,&#39;test-vhost&#39;); 动态匹配模型生产者 protected function execute(InputInterface $input, OutputInterface $output): int &#123; $connection = new AMQPStreamConnection(&#39;192.168.106.179&#39;, 5672, &#39;guest&#39;, &#39;guest&#39;); // 创建通道 $channel = $connection-&gt;channel(); $channel-&gt;exchange_declare(&#39;order.lifecycle&#39;, AMQPExchangeType::TOPIC, false, false, false); //定义一个默认 全状态队列 $channel-&gt;queue_declare(&#39;order.all&#39;); //匹配 全状态 订单消息 $channel-&gt;queue_bind(&#39;order.all&#39;, &#39;order.lifecycle&#39;, &#39;order.*&#39;); $faker = Factory::create(&#39;zh_CN&#39;); $orderStatus = [ self::ORDER_CREATE, self::ORDER_SENDED, self::ORDER_WAIT_PAY ]; $status = $orderStatus[array_rand($orderStatus)]; $body = [ &#39;status&#39; =&gt; $status, &#39;name&#39; =&gt; $faker-&gt;name, &#39;order_no&#39; =&gt; $faker-&gt;uuid ]; dump($body); $msg = new AMQPMessage(json_encode($body), [&#39;delivery_mode&#39; =&gt; AMQPMessage::DELIVERY_MODE_PERSISTENT]); //消息 动态 绑定 路由键 $channel-&gt;basic_publish($msg, &#39;order.lifecycle&#39;,&#39;order.&#39;.$status); return Command::SUCCESS; &#125; 消费者 public function handPay() &#123; $connection = new AMQPStreamConnection(&#39;192.168.106.179&#39;, 5672, &#39;guest&#39;, &#39;guest&#39;); // 创建通道 $channel = $connection-&gt;channel(); //定义 h66 消费 pay 队列 $channel-&gt;queue_declare(&#39;h66.pay&#39;); //将 WAIY_PAY 类型消息 绑定到该队列 $channel-&gt;queue_bind(&#39;h66.pay&#39;, &#39;order.lifecycle&#39;, &#39;order.WAIT_PAY&#39;); $callback = function($msg) &#123; $body = json_decode($msg-&gt;body, true); $this-&gt;info(&quot;处理数据...&#123;$body[&#39;status&#39;]&#125; &#123;$body[&#39;order_no&#39;]&#125;&quot;); &#125;; // 消费 队列 $channel-&gt;basic_consume(&#39;h66.pay&#39;, &#39;&#39;, false, true, false, false, $callback); // 阻塞队列监听事件 while ($channel-&gt;is_open()) &#123; $channel-&gt;wait(); &#125; &#125; 代码示例中 生成者根据订单状态动态生产相应路由键消息到交换机，消费者订阅自己所需的状态到自己的队列当中进行消费。 例如 handPay 消费者只订阅待支付类型。 参考 https://rabbitmq.mr-ping.com/ https://www.rabbitmq.com/getstarted.html","categories":[],"tags":[{"name":"架构","slug":"架构","permalink":"http://visonforcoding.xyz/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"mysql的waitimeout","slug":"mysql的waitimeout","date":"2021-06-02T12:33:18.000Z","updated":"2021-06-25T01:30:20.857Z","comments":true,"path":"2021/06/02/mysql的waitimeout/","link":"","permalink":"http://visonforcoding.xyz/2021/06/02/mysql%E7%9A%84waitimeout/","excerpt":"首先，我们来看下 show GLOBAL VARIABLES like &#39;%timeout%&#39;; 默认值为28800s即8小时,我们改为100s # Default Homebrew MySQL server config [mysqld] # Only allow connections from localhost bind-address = 0.0.0.0 wait_timeout=100 interactive_timeout=100 重新查看结果","text":"首先，我们来看下 show GLOBAL VARIABLES like &#39;%timeout%&#39;; 默认值为28800s即8小时,我们改为100s # Default Homebrew MySQL server config [mysqld] # Only allow connections from localhost bind-address = 0.0.0.0 wait_timeout=100 interactive_timeout=100 重新查看结果 查看对守护进程连接的影响 public function longT() &#123; $TicketModel = new TicketModel(); $this-&gt;success(&#39;开始建立连接...&#39;); while (true) &#123; sleep(120); dump($TicketModel-&gt;select(&#39;t_id&#39;)-&gt;fetch()); &#125; &#125; 发现在100s后的连接已被主动断开 代码中的场景是，在wait_timeout之内无任何操作会自动关闭 官方解释interactive_timeout 28800 The number of seconds the server waits for activity on an interactive connection before closing it. An interactive client is defined as a client that uses the CLIENT_INTERACTIVE option to mysql_real_connect(). See also wait_timeout. waitimeout 28800 The number of seconds the server waits for activity on a noninteractive connection before closing it. On thread startup, the session wait_timeout value is initialized from the global wait_timeout value or from the global interactive_timeout value, depending on the type of client (as defined by the CLIENT_INTERACTIVE connect option to mysql_real_connect()). See also interactive_timeout. 通过MySQL客户端连接db的是交互会话，通过jdbc等程序连接db的是非交互会话。 总结： 如果应用程序长时间的使用一个连接，而有机会长时间不进行任何操作。则会导致连接被关闭。 参考文献: 1.https://dev.mysql.com/doc/refman/5.7/en/server-system-variables.html2.https://cloud.tencent.com/developer/article/1181515","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://visonforcoding.xyz/tags/mysql/"}]},{"title":"vue+quasar+electron+springboot+mysql撸一个TODO LIST 看板","slug":"vue-quasar-electron-springboot-mysql撸一个TODO-LIST-看板","date":"2021-04-09T03:39:08.000Z","updated":"2021-04-09T03:52:17.199Z","comments":true,"path":"2021/04/09/vue-quasar-electron-springboot-mysql撸一个TODO-LIST-看板/","link":"","permalink":"http://visonforcoding.xyz/2021/04/09/vue-quasar-electron-springboot-mysql%E6%92%B8%E4%B8%80%E4%B8%AATODO-LIST-%E7%9C%8B%E6%9D%BF/","excerpt":"先看效果 写本项目的目的有几点： 学习下vue+electron桌面开发 学习下java和spring开发(本人一直使用PHP) 一直缺少一款能适合自己的TODO LIST软件，能有桌面端的","text":"先看效果 写本项目的目的有几点： 学习下vue+electron桌面开发 学习下java和spring开发(本人一直使用PHP) 一直缺少一款能适合自己的TODO LIST软件，能有桌面端的 可直接打包成dmg、exe 等二进制文件使用。这是我打包后的效果。 技术栈 vue quasar electron springboot mysql 自定义注解源码地址 前端 https://github.com/visonforcoding/carambola-todo 后端 https://github.com/visonforcoding/carambola-todo-service","categories":[],"tags":[{"name":"web","slug":"web","permalink":"http://visonforcoding.xyz/tags/web/"}]},{"title":"并发编程日记-线程不安全的危害","slug":"编发编程日记-线程不安全的危害","date":"2021-03-03T11:16:37.000Z","updated":"2021-03-15T13:27:22.490Z","comments":true,"path":"2021/03/03/编发编程日记-线程不安全的危害/","link":"","permalink":"http://visonforcoding.xyz/2021/03/03/%E7%BC%96%E5%8F%91%E7%BC%96%E7%A8%8B%E6%97%A5%E8%AE%B0-%E7%BA%BF%E7%A8%8B%E4%B8%8D%E5%AE%89%E5%85%A8%E7%9A%84%E5%8D%B1%E5%AE%B3/","excerpt":"","text":"计数器@WebServlet(name = &quot;HelloServlet&quot;, urlPatterns = &#123;&quot;/hello&quot;&#125;) public class HelloServlet extends HttpServlet &#123; private static final Logger LOG = Logger.getLogger(HelloServlet.class.getName()); private Integer count = 0; @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; ++count; processRequest(request, response); LOG.info(String.format(&quot;计数 %d&quot;, count)); &#125; &#125; 按常理多少次请求后就会打印出计数多少。 ab -n300 -c20 http://localhost:8080/servlet-demo/hello正常下，执行第一次 计数应为300 事实上得到的却不是 再执行.. 2 ~ 5903 ~ 8794 ~ 1170 几乎没有规律，并不是预期的 300的倍数。 解释实际上++count是一个读取-修改-写入的操作。 假设线程A、B 同时读取到了值是m,同时写入+1后的值m+1。结果count = m+1,则事实上整个计数就少了1,应该为m+2。 处理将count声明为AtomicInter private Integer count = 0; private AtomicInteger atomicCount = new AtomicInteger(0); @Override protected void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; ++count; processRequest(request, response); LOG.info(String.format(&quot;计数count %d&quot;, count)); LOG.info(String.format(&quot;计数atomicCount %d&quot;, atomicCount.incrementAndGet())); &#125; 可以看到，AtomicInteger统计的是正确的了。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"spring-boot记录sql探索","slug":"java/spring-boot记录sql探索","date":"2021-02-23T11:28:29.000Z","updated":"2021-02-24T06:42:23.991Z","comments":true,"path":"2021/02/23/java/spring-boot记录sql探索/","link":"","permalink":"http://visonforcoding.xyz/2021/02/23/java/spring-boot%E8%AE%B0%E5%BD%95sql%E6%8E%A2%E7%B4%A2/","excerpt":"目标记录每次请求内的http、es、mysql耗时，本篇讨论mysql部分 为什么说要探索，这不是很简单的事么？但是能满足以下几点么？ 能记录limit等参数 能将参数和sql写一起，能直接使用 能记录耗时 能计数累加,统计一次请求中sql执行的总数和总耗时","text":"目标记录每次请求内的http、es、mysql耗时，本篇讨论mysql部分 为什么说要探索，这不是很简单的事么？但是能满足以下几点么？ 能记录limit等参数 能将参数和sql写一起，能直接使用 能记录耗时 能计数累加,统计一次请求中sql执行的总数和总耗时 spring原生能力logging.level.org.hibernate.SQL=debug logging.level.org.hibernate.type.descriptor.sql.BasicBinder=trace 通过上面两条配置。 ✔️可以显示sql. ❌不能和参数一行显示 ❌不能显示limit参数 ❌不能计数和记录耗时 2021-02-23 19:35:42.932 DEBUG 97586 --- [ restartedMain] org.hibernate.SQL : select admin0_.id as id1_0_, admin0_.create_time as create_t2_0_, admin0_.modify_time as modify_t3_0_, admin0_.email as email4_0_, admin0_.password as password5_0_, admin0_.status as status6_0_, admin0_.username as username7_0_ from admin admin0_ where admin0_.username=? 2021-02-23 19:35:42.949 TRACE 97586 --- [ restartedMain] o.h.type.descriptor.sql.BasicBinder : binding parameter [1] as [VARCHAR] - [root]原生log+org.hibernate.EmptyInterceptororg.hibernate.EmptyInterceptor提供钩子，hibernate本身提供entity的curd钩子。重写EmptyInterceptor方法，可以实现计数。但是onPrepareStatement方法只是装配sql前的事件，而且不是完整的sql。 ✔️ 可以显示sql ❌ 不能和参数一行显示 ❌ 不能显示limit参数 ✔️ 能计数 ❌ 不能记录耗时 spring.jpa.properties.hibernate.ejb.interceptor=com.vison.itdoc.config.HibernateInterceptor public class HibernateInterceptor extends EmptyInterceptor &#123; @Override public boolean onLoad(Object entity, Serializable id, Object[] state, String[] propertyNames, Type[] types) &#123; // Log.info(&quot;onload...&quot;, entity) return true; &#125; @Override public String onPrepareStatement(String string) &#123; // count++ return INSTANCE.onPrepareStatement(string); &#125; @Override public void afterTransactionCompletion(Transaction t) &#123; INSTANCE.afterTransactionCompletion(t); Log.info(&quot;after trans complete&quot;, t); &#125; &#125; log4jdbclog4jdbc能很好的解决sql完整显示和记录耗时的问题 2021-02-23 19:59:13.709 INFO 97586 --- [nio-8081-exec-1] jdbc.sqltiming : select posts0_.id as id1_2_, posts0_.create_time as create_t2_2_, posts0_.modify_time as modify_t3_2_, posts0_.content as content4_2_, posts0_.title as title5_2_ from posts posts0_ where 1=1 order by posts0_.id asc limit 10 ; &#123;executed in 1 msec&#125;还能够定义超过1定时间的执行sql记录为error类型。 &lt;dependency&gt; &lt;groupId&gt;com.googlecode.log4jdbc&lt;/groupId&gt; &lt;artifactId&gt;log4jdbc&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt; &lt;/dependency&gt; spring.datasource.driver-class-name: net.sf.log4jdbc.DriverSpy #使用log4jdbc后mysql的url spring.datasource.url=jdbc:log4jdbc:mysql://localhost:3306/xxxx?useUnicode=true&amp;characterEncoding=UTF-8 #使用log4jdbc后oracle的url #spring.datasource.url: jdbc:log4jdbc:oracle:thin:@127.0.0.1:1521:orcl 注意需要添加spring.datasource.driver-class-name 和更改 spring.datasource.url 将jdbc改为 jdbc:log4jdbc log4jdbc.properties可以定义更多配置 #配置为需要记录的包或类匹配路径 #log4jdbc.debug.stack.prefix=com.drp #log4jdbc加载的drivers (驱动名) #log4jdbc.drivers=oracle.jdbc.OracleDriver log4jdbc.auto.load.popular.drivers=true #在日志中显示warn警告 log4jdbc.statement.warn=true #毫秒值.执行时间超过该值的SQL语句将被记录为warn级别. log4jdbc.sqltiming.warn.threshold=2000 #毫秒值.执行时间超过该值的SQL语句将被记录为error级别. log4jdbc.sqltiming.error.threshold=3000 #是把boolean记录为 &#39;true&#39;/&#39;false&#39; 还是 1/0. 默认设置为false,不启用,为了移植性. #log4jdbc.dump.booleanastruefalse=true #输出的sql,一行最大的字符数，默认90. 以后新版可能为0 #log4jdbc.dump.sql.maxlinelength=90 #如果在调试模式下转储，则转储整个堆栈跟踪 默认false log4jdbc.dump.fulldebugstacktrace=false #是否记录某些类型的语句，默认true log4jdbc.dump.sql.select=true log4jdbc.dump.sql.insert=true log4jdbc.dump.sql.delete=true log4jdbc.dump.sql.update=true log4jdbc.dump.sql.create=true #输出sql末尾处加入分号，默认false log4jdbc.dump.sql.addsemicolon=true #将此设置为false以不修剪已记录的SQL log4jdbc.trim.sql=true #将此设置为false不删除额外的空行 log4jdbc.trim.sql.extrablanklines=true #log4jdbc.suppress.generated.keys.exception=false ✔️ 可以显示sql ✔️ 不能和参数一起显示 ✔️ 不能显示limit参数 ❌ 能计数 ✔️ 能记录单个sql耗时 ❌ 不能统计总耗时 不足的是，单纯log4jdbc并不能满足所有。理论上log4jdbc+org.hibernate.EmptyInterceptor可以满足需求了 P6Spy测试完毕，发现P6Spy目前最能满足需求： ✔️ 可以显示sql ✔️ 不能和参数一起显示 ✔️ 不能显示limit参数 ✔️ 能计数 ✔️ 不能记录耗时 ✔️ 支持curd事件前后钩子，钩子参数返回sql和执行耗时及异常信息🚀 &lt;dependency&gt; &lt;groupId&gt;p6spy&lt;/groupId&gt; &lt;artifactId&gt;p6spy&lt;/artifactId&gt; &lt;version&gt;3.9.1&lt;/version&gt; &lt;/dependency&gt; 同log4jdbc需要改driver和url spring.datasource.driver-class-name=com.p6spy.engine.spy.P6SpyDriver spring.datasource.url=jdbc:p6spy:mysql://localhost:3306/test?useLegacyDatetimeCode=false&amp;serverTimezone=UTC psy.properties可以定义更多配置 #modulelist=com.p6spy.engine.spy.P6SpyFactory,com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory modulelist=com.vison.itdoc.config.CustomeP6Factory,com.p6spy.engine.logging.P6LogFactory,com.p6spy.engine.outage.P6OutageFactory #moduelist很关键，我这里使用了自定义的Factory，因为我需要自定义event appender=com.p6spy.engine.spy.appender.Slf4JLogger logMessageFormat=com.p6spy.engine.spy.appender.CustomLineFormat customLogMessageFormat=%(executionTime) ms|%(category)|%(sql) excludecategories=result,resultset,info,debug 正常使用默认配置就可以显示出sql和耗时信息 4 ms|statement|select admin0_.id as id1_0_, admin0_.create_time as create_t2_0_, admin0_.modify_time as modify_t3_0_, admin0_.email as email4_0_, admin0_.password as password5_0_, admin0_.status as status6_0_, admin0_.username as username7_0_ from admin admin0_ where admin0_.username=&#39;root&#39;可以看到，耗时信息和实际参数 自定义事件modulelist=com.p6spy.engine.spy.P6SpyFactory改成自定义Factory 自定义Factory public class CustomeP6Factory implements com.p6spy.engine.spy.P6Factory &#123; @Override public P6LoadableOptions getOptions(P6OptionsRepository optionsRepository) &#123; return new P6SpyOptions(optionsRepository); &#125; @Override public JdbcEventListener getJdbcEventListener() &#123; return new P6spyListener(); //使用自定义Listener &#125; &#125; 自定义事件 public class P6spyListener extends JdbcEventListener &#123; @Override public void onAfterExecuteQuery(PreparedStatementInformation statementInformation, long timeElapsedNanos, SQLException e) &#123; App.sqlCount.incrementAndGet(); Log.info(&quot;execute query...&quot;, statementInformation.getSqlWithValues()); &#125; @Override public void onAfterExecuteUpdate(PreparedStatementInformation statementInformation, long timeElapsedNanos, int rowCount, SQLException e) &#123; App.sqlCount.incrementAndGet(); Log.info(&quot;execute update..&quot;, statementInformation.getSqlWithValues()); &#125; @Override public void onAfterExecute(StatementInformation statementInformation, long timeElapsedNanos, String sql, SQLException e) &#123; Log.info(&quot;execute..&quot;, statementInformation.getSqlWithValues()); &#125; &#125; 可以看到，我在自定义事件中进行了sql计数.于是我可以在请求结束时打印每次请求的总sql执行次数。 public class RequestInitInterceptor implements HandlerInterceptor &#123; public RequestInitInterceptor() &#123; &#125; @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; App._uniq_req_no = UUID.randomUUID().toString(); App.sqlCount = new AtomicInteger(0); Log.setMsgTraceNo(App._uniq_req_no); Log.info(&quot;request start...&quot;, handler); return true; &#125; @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; Log.info(String.format(&quot;finish request sql执行次数:%s&quot;, App.sqlCount)); &#125; &#125; 由于事件参数还给出了timeElapsedNanos,最终我们还能统计出所有sql执行的耗时。这样一来我们就能看出一次请求内，最耗时的操作具体是什么。达到类似以下效果： 参考 Counting Queries per Request with Hibernate and Spring register an event handler","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"spring-boot+vue+supervisor+nginx的前后端分离部署","slug":"java/spring-boot-vue的前后端分离部署","date":"2021-02-22T06:43:54.000Z","updated":"2021-08-23T08:58:08.832Z","comments":true,"path":"2021/02/22/java/spring-boot-vue的前后端分离部署/","link":"","permalink":"http://visonforcoding.xyz/2021/02/22/java/spring-boot-vue%E7%9A%84%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%83%A8%E7%BD%B2/","excerpt":"要保证同域部署,因为跨域会有很多问题要重新解决 顺便树下，但其实现在互联网产品一般都有多客户端，pc web 、小程序、app。保守的同域session模式保持会话已经满足不了一些需求。比如，单端登录等。 言归正传，我采取的思路是，前端请求接口时统一加上api前缀，nginx将api前缀的路由请求代理转发到spring-boot","text":"要保证同域部署,因为跨域会有很多问题要重新解决 顺便树下，但其实现在互联网产品一般都有多客户端，pc web 、小程序、app。保守的同域session模式保持会话已经满足不了一些需求。比如，单端登录等。 言归正传，我采取的思路是，前端请求接口时统一加上api前缀，nginx将api前缀的路由请求代理转发到spring-boot nginx配置 server &#123; server_name admin.domain.xyz; index index.html; location / &#123; index index.html; root /home/wwwuser/webroot/itdoc-admin-web/dist/spa; &#125; location /api/ &#123; proxy_pass http://127.0.0.1:8081/; &#125; # optionally disable falling back to PHP script for the asset directories; # nginx will return a 404 error when files are not found instead of passing the # request to Symfony (improves performance but Symfony&#39;s 404 page is not displayed) # location /bundles &#123; # try_files $uri =404; # &#125; error_log /var/log/nginx/admin_error.log; access_log /var/log/nginx/admin_access.log; &#125; supervisor守护java -jar我这里采取java -jar模式部署，但是单纯的这种模式并不能保证自启动和进程监控等。因此需要借助supervisor。 [program:itdoc] command=/usr/local/jdk-11.0.2/bin/java -jar itdoc-0.0.2-SNAPSHOT.jar process_name=%(program_name)s numprocs=1 directory=/home/wwwuser/webroot umask=022 priority=999 autostart=true autorestart=unexpected startsecs=10 startretries=3 exitcodes=0 stopsignal=TERM stopwaitsecs=10 stopasgroup=false killasgroup=false user=wwwuser redirect_stderr=false stdout_logfile=/var/log/webroot/itdoc-out.log stdout_logfile_maxbytes=1MB stdout_logfile_backups=10 stdout_capture_maxbytes=1MB stdout_events_enabled=false stderr_logfile=/var/log/webroot/itdoc-err.log stderr_logfile_maxbytes=1MB stderr_logfile_backups=10 stderr_capture_maxbytes=1MB 这里的autostart 和 autorestart 能保证自启动和启动重启","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"利用Locust进行性能测试","slug":"利用Locust进行性能测试","date":"2021-01-23T02:17:02.000Z","updated":"2021-04-30T07:19:09.408Z","comments":true,"path":"2021/01/23/利用Locust进行性能测试/","link":"","permalink":"http://visonforcoding.xyz/2021/01/23/%E5%88%A9%E7%94%A8Locust%E8%BF%9B%E8%A1%8C%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95/","excerpt":"要看一个项目的最大可用能力是多少，性能测试工作少不了. 每一个项目都应该做压测 多线程并发模型一定要做压测","text":"要看一个项目的最大可用能力是多少，性能测试工作少不了. 每一个项目都应该做压测 多线程并发模型一定要做压测 安装$ pip3 install locust编写脚本import time from locust import HttpUser, task, between class QuickstartUser(HttpUser): wait_time = between(1, 2.5) @task def hello_world(self): self.client.get(&quot;/hello&quot;) self.client.get(&quot;/world&quot;) @task(3) def view_items(self): for item_id in range(10): self.client.get(f&quot;/item?id=&#123;item_id&#125;&quot;, name=&quot;/item&quot;) time.sleep(1) def on_start(self): self.client.post(&quot;/login&quot;, json=&#123;&quot;username&quot;:&quot;foo&quot;, &quot;password&quot;:&quot;bar&quot;&#125;) wait_time = between(1, 2.5) Our class defines a wait_time that will make the simulated users wait between 1 and 2.5 seconds after each task (see below) is executed. For more info see wait_time attribute. def hello_world(self): @task def hello_world(self): self.client.get(&quot;/hello&quot;) self.client.get(&quot;/world&quot;) @task(3) def view_items(self): ... task(3) 内的参数表示任务执行的权重，view_items的次数将是hello_world次数的3倍。 执行$ locust -f locust_files/my_locust_file.py 任务执行界面和结果","categories":[],"tags":[{"name":"软件工程","slug":"软件工程","permalink":"http://visonforcoding.xyz/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"}]},{"title":"黑启动","slug":"黑启动","date":"2021-01-21T13:38:28.000Z","updated":"2021-06-03T03:51:07.759Z","comments":true,"path":"2021/01/21/黑启动/","link":"","permalink":"http://visonforcoding.xyz/2021/01/21/%E9%BB%91%E5%90%AF%E5%8A%A8/","excerpt":"","text":"facebook案例作为黑启动流程的一部分，每个Facebook 用户会话（在用户端浏览器中运行JavaScript 代码）都加载了测试工具。虽然聊天功能的用户界面元素被隐藏起来，但浏览器还是会向已部署在生产环境中的后台聊天服务器发送用户不可见的聊天测试信息，这使开 发团队能够在整个项目过程中模拟出类生产负载，从而在发布之前找出并解决性能问题。 老子惊了,这有点牛皮","categories":[],"tags":[]},{"title":"servlet集成mybatis-无xml&注解方式","slug":"java/servlet集成mybatis-无xml-注解方式","date":"2021-01-06T08:14:24.000Z","updated":"2021-01-06T08:40:27.772Z","comments":true,"path":"2021/01/06/java/servlet集成mybatis-无xml-注解方式/","link":"","permalink":"http://visonforcoding.xyz/2021/01/06/java/servlet%E9%9B%86%E6%88%90mybatis-%E6%97%A0xml-%E6%B3%A8%E8%A7%A3%E6%96%B9%E5%BC%8F/","excerpt":"习惯了php项目之后，恐怕非常不喜欢操作xml吧.本章将介绍servlet+mybatis无xml配置模式。","text":"习惯了php项目之后，恐怕非常不喜欢操作xml吧.本章将介绍servlet+mybatis无xml配置模式。 依赖 &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.26&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.6&lt;/version&gt; &lt;/dependency&gt; 引入首先定义datasource public class DatabaseConfig &#123; static String driver = &quot;com.mysql.jdbc.Driver&quot;; static String url = &quot;jdbc:mysql://localhost:3306/db_itdoc?useSSL=false&quot;; static String username = &quot;root&quot;; static String password = &quot;12345678&quot;; public static DataSource getDataSource() &#123; Properties properties = new Properties(); properties.setProperty(&quot;driver&quot;, driver); properties.setProperty(&quot;url&quot;, url); properties.setProperty(&quot;username&quot;, username); properties.setProperty(&quot;password&quot;, password); UnpooledDataSourceFactory unpooledDataSourceFactory = new UnpooledDataSourceFactory(); unpooledDataSourceFactory.setProperties(properties); DataSource dataSource = unpooledDataSourceFactory.getDataSource(); return dataSource; &#125; &#125; 获取sessionFactory public class MybatisLoader &#123; static SqlSessionFactory sqlSessionFactory = null; public static SqlSessionFactory getSqlSessionFactory() &#123; if (sqlSessionFactory == null) &#123; DataSource dataSource = DatabaseConfig.getDataSource(); TransactionFactory transactionFactory = new JdbcTransactionFactory(); Environment environment = new Environment(&quot;development&quot;, transactionFactory, dataSource); Configuration configuration = new Configuration(environment); configuration.addMapper(UserMapper.class); sqlSessionFactory = new SqlSessionFactoryBuilder().build(configuration); &#125; return sqlSessionFactory; &#125; &#125; 定义mapperpublic interface UserMapper &#123; @Select(&quot;SELECT * FROM user WHERE id = #&#123;id&#125;&quot;) User selectUser(int id); @Insert(&quot;INSERT INTO user(name,email) VALUES(#&#123;name&#125;, #&#123;email&#125;)&quot;) int insertUser(User user); &#125; 查询和插入public class UserController &#123; public UserController() &#123; &#125; @GetMapping(path = &quot;/user/profile&quot;) public String profile(HttpServletRequest request, HttpServletResponse response) &#123; System.out.print(request.getCookies()); return &quot;i am user profile&quot;; &#125; @GetMapping(path = &quot;/user&quot;) public Response user(HttpServletRequest request, int id) &#123; User user = null; SqlSession session = MybatisLoader.getSqlSessionFactory().openSession(); UserMapper mapper = session.getMapper(UserMapper.class); user = mapper.selectUser(id); return new Response(0, &quot;获取成功&quot;, user); &#125; @PostMapping(path = &quot;/user/add&quot;) public Response add(User user) &#123; Log.info(&quot;request user&quot;, user); try &#123; SqlSession session = MybatisLoader.getSqlSessionFactory().openSession(); UserMapper mapper = session.getMapper(UserMapper.class); int id = mapper.insertUser(user); session.commit(); Log.debug(&quot;返回&quot;, id); &#125; catch (Exception e) &#123; Log.error(&quot;保存失败&quot;, e); &#125; return new Response(0, &quot;保存&quot;, user); &#125; &#125;","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"javaweb开发","slug":"java/手撕javaweb开发","date":"2020-12-22T06:17:22.228Z","updated":"2021-07-07T07:11:34.141Z","comments":true,"path":"2020/12/22/java/手撕javaweb开发/","link":"","permalink":"http://visonforcoding.xyz/2020/12/22/java/%E6%89%8B%E6%92%95javaweb%E5%BC%80%E5%8F%91/","excerpt":"","text":"本系列文章将以几乎0基础javaweb为背景手写一个javaweb框架并进行开发。 背景 0基础javaweb,没有javaweb开发的实际经验 有多年PHPweb实战经验 有一定java语法基础 有5分(满分100)的spring boot知识储备，毕竟用spring boot启动一个hello world还是比较简单的。 宗旨本文宗旨是想通过手写java web框架的方式，让有其他语言web开发经验的同事能由浅入深学会java web开发和理解其中原理。本系列文章将有以下几点原则。 注重实践，一定会有源代码运行成功案例 有理有据，一些实现必须有官方或权威文献解释 更新目录 手撕javaweb-HTTP前世","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"log4j使用指南","slug":"java/log4j使用指南","date":"2020-12-21T06:28:40.445Z","updated":"2021-08-23T09:15:09.466Z","comments":true,"path":"2020/12/21/java/log4j使用指南/","link":"","permalink":"http://visonforcoding.xyz/2020/12/21/java/log4j%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97/","excerpt":"对于刚开始接触java的人来说，用什么来打日志似乎快被java的这么多概念搞懵了。log4j、log4j2、slf4j、logback?!!","text":"对于刚开始接触java的人来说，用什么来打日志似乎快被java的这么多概念搞懵了。log4j、log4j2、slf4j、logback?!! 盘点盘点下我们遇到过哪些日志 java.util.logging org.apache.commons.logging.Log Log4j和Log4j2 SLF4J 和 Logback 简单概括 Log4j和Log4j2是commons.logging log4jApache Log4j 是一个非常古老的日志框架，并且是多年来最受欢迎的日志框架。 它引入了现代日志框架仍在使用的基本概念，如分层日志级别和记录器。 2015 年 8 月 5 日，该项目管理委员会宣布 Log4j 1.x 已达到使用寿命。 建议用户使用 Log4j 1 升级到 ApacheLog4j 2。 log4j2Apache Log4j 2是对 Log4j 的升级，它比其前身 Log4j 1.x 提供了重大改进，并提供了 Logback 中可用的许多改进，同时修复了 Logback 架构中的一些固有问题。 与 Logback 一样，Log4j2 提供对 SLF4J 的支持，自动重新加载日志配置，并支持高级过滤选项。 除了这些功能外，它还允许基于 lambda 表达式对日志语句进行延迟评估，为低延迟系统提供异步记录器，并提供无垃圾模式以避免由垃圾收集器操作引起的任何延迟。 所有这些功能使 Log4j2 成为这三个日志框架中最先进和最快的。 Logbacklogback 是由 log4j 创始人设计的又一个开源日志组件，作为流行的 log4j 项目的后续版本，从而替代 log4j。 Logback 的体系结构足够通用，以便在不同情况下应用。 目前，logback 分为三个模块：logback-core，logback-classic和logback-access。 logback-core：模块为其他两个模块的基础。logback-classic：模块可以被看做是log4j的改进版本。此外，logback-classic 本身实现了 SLF4J API，因此可以在 logback 和其他日志框架（如 log4j 或 java.util.logging（JUL））之间来回切换。logback-access：模块与 Servlet 容器（如 Tomcat 和 Jetty）集成，以提供 HTTP 访问日志功能。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"HTTP本质","slug":"java/春天之前-http","date":"2020-12-18T08:52:25.195Z","updated":"2021-06-03T07:01:45.699Z","comments":true,"path":"2020/12/18/java/春天之前-http/","link":"","permalink":"http://visonforcoding.xyz/2020/12/18/java/%E6%98%A5%E5%A4%A9%E4%B9%8B%E5%89%8D-http/","excerpt":"试图跳过spring,而学习spring boot是不可能的。学习java web开发，从基础开始学习。就应当了解http、servlet、tomcat","text":"试图跳过spring,而学习spring boot是不可能的。学习java web开发，从基础开始学习。就应当了解http、servlet、tomcat 起源 它解决什么问题 实现原理 起源1980年6月至12月间，伯纳斯-李在的CERN（欧洲核子研究组织）担任工作。实验室的研究人员需要大量的信息查阅或沟通。在那段时间里，他提出了个构想：创建一个以超文本系统为基础的项目，方便研究人员分享及更新讯息。 1989年3月，他写下了他的初步构想，并在1990年重新配置。然后被他的经理麦克·森德尔（Mike Sendall）所接受。他使用与ENQUIRE系统相似的概念来创建万维网，为此他设计并构建了第一个网页浏览器。 世界上第一个网站在CERN搭建，而CERN则位于法国边境。网站在1991年8月6日上线。 上线 的第一个网址，http://info.cern.ch/hypertext/WWW/TheProject.html 告诉人们万维网是什么，用户如何使用浏览器，如何创建网页服务器。 目的设计HTTP最初的目的是为了提供一种发布和接收HTML页面的方法。 实现一个连接是由传输层来控制的，这从根本上不属于HTTP的范围。HTTP并不需要其底层的传输层协议是面向连接的，只需要它是可靠的，或不丢失消息的（至少返回错误）。在互联网中，有两个最常用的传输层协议：TCP是可靠的，而UDP不是。因此，HTTP依赖于面向连接的TCP进行消息传递，但连接并不是必须的。因此通过socket编程就能实现http协议。 public class Server &#123; private static int port = 8081; public static void main(String[] args) throws IOException &#123; ServerSocket ss = new ServerSocket(port); // 监听指定端口 System.out.println(&quot;server is running...&quot;); for (;;) &#123; Socket sock = ss.accept(); System.out.println(&quot;connected from &quot; + sock.getRemoteSocketAddress()); Thread t = new Handler(sock); t.start(); &#125; &#125; &#125; public class Handler extends Thread &#123; Socket sock; public Handler(Socket sock) &#123; this.sock = sock; &#125; public void run() &#123; try ( InputStream input = this.sock.getInputStream()) &#123; try ( OutputStream output = this.sock.getOutputStream()) &#123; handle(input, output); &#125; &#125; catch (Exception e) &#123; try &#123; this.sock.close(); &#125; catch (IOException ioe) &#123; &#125; System.out.println(&quot;client disconnected.&quot;); &#125; &#125; private void handle(InputStream input, OutputStream output) throws IOException &#123; System.out.println(&quot;Process new http request...&quot;); var reader = new BufferedReader(new InputStreamReader(input, StandardCharsets.UTF_8)); var writer = new BufferedWriter(new OutputStreamWriter(output, StandardCharsets.UTF_8)); // 读取HTTP请求: boolean requestOk = false; String first = reader.readLine(); if (first.startsWith(&quot;GET / HTTP/1.&quot;)) &#123; requestOk = true; &#125; for (;;) &#123; String header = reader.readLine(); if (header.isEmpty()) &#123; // 读取到空行时, HTTP Header读取完毕 break; &#125; System.out.println(header); &#125; System.out.println(requestOk ? &quot;Response OK&quot; : &quot;Response Error&quot;); if (!requestOk) &#123; // 发送错误响应: writer.write(&quot;HTTP/1.0 404 Not Found\\r\\n&quot;); writer.write(&quot;Content-Length: 0\\r\\n&quot;); writer.write(&quot;\\r\\n&quot;); writer.flush(); &#125; else &#123; // 发送成功响应: String data = &quot;&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello, world!&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;&quot;; int length = data.getBytes(StandardCharsets.UTF_8).length; writer.write(&quot;HTTP/1.0 200 OK\\r\\n&quot;); writer.write(&quot;Connection: close\\r\\n&quot;); writer.write(&quot;Content-Type: text/html\\r\\n&quot;); writer.write(&quot;Content-Length: &quot; + length + &quot;\\r\\n&quot;); writer.write(&quot;\\r\\n&quot;); // 空行标识Header和Body的分隔 writer.write(data); writer.flush(); &#125; // TODO: 处理HTTP请求 &#125; &#125; 参考 https://developer.mozilla.org/zh-CN/docs/Web/HTTP 廖雪峰-web基础","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"Introduction to Spring MVC HandlerInterceptor拦截器介绍","slug":"java/Introduction-to-Spring-MVC-HandlerInterceptor拦截器介绍","date":"2020-09-24T06:41:22.000Z","updated":"2020-09-24T06:41:36.296Z","comments":true,"path":"2020/09/24/java/Introduction-to-Spring-MVC-HandlerInterceptor拦截器介绍/","link":"","permalink":"http://visonforcoding.xyz/2020/09/24/java/Introduction-to-Spring-MVC-HandlerInterceptor%E6%8B%A6%E6%88%AA%E5%99%A8%E4%BB%8B%E7%BB%8D/","excerpt":"","text":"","categories":[],"tags":[{"name":"JAVA","slug":"JAVA","permalink":"http://visonforcoding.xyz/tags/JAVA/"}]},{"title":"Java JPA思考","slug":"java/Java-JPA思考","date":"2020-09-23T08:56:11.000Z","updated":"2020-12-21T01:33:58.565Z","comments":true,"path":"2020/09/23/java/Java-JPA思考/","link":"","permalink":"http://visonforcoding.xyz/2020/09/23/java/Java-JPA%E6%80%9D%E8%80%83/","excerpt":"JPA即Java Persistence API. 2006年5月11号，JPA 1.0 规范作为 JCP JSR 220 的一部分最终被发布。 在PHP世界当中doctrine、cake ORM 都有JPA的影子。","text":"JPA即Java Persistence API. 2006年5月11号，JPA 1.0 规范作为 JCP JSR 220 的一部分最终被发布。 在PHP世界当中doctrine、cake ORM 都有JPA的影子。 Entity持久化实体是一个轻量级的 Java 类，其状态通常持久地保存到关系数据库的表中。 这种实体的实例对应于表中的各个行。 实体之间通常有关系，这些关系通过对象/关系元数据表示。 可以在实体类文件中直接使用注释来指定这种关系，也可以在随应用程序分发的单独XML描述文件中指定。 JPQLJava持久化查询语言 （JPQL）对存储在关系数据库中的实体进行查询。查询在语法上类似于SQL查询，但是操作的是实体对象而不是直接对数据库表进行操作。 动机在引入EJB 3.0规范之前，许多企业级Java开发人员使用由持久化框架（例如Hibernate）或数据访问对象（DAO）提供的轻量级持久化对象，来代替实体bean（EJB的一种）。 这是因为在以前的EJB规范中，实体bean需要太多复杂的代码和繁重的资源占用，并且由于bean和DAO对象或持久化框架之间的源代码中的互连和依赖性，它们只能在Java EE应用程序服务器中使用。 因此，最初在第三方持久性框架中提供的许多功能都被合并到Java Persistence API中，并且从2006年开始，像Hibernate（版本3.2）和TopLink Essentials这样的项目已经实现Java Persistence API规范。 JPA提供商JPA是一个开源API，因此Oracle，Redhat，Eclipse等各种企业供应商通过在其中添加JPA持久性风格来提供新产品。 其中一些产品包括: Hibernate, Eclipselink, Toplink, Spring Data JPA, etc. JSR定义了标准，众多组织对这个标准进行了实现，这使得开发者几乎可以在不同的实现版本里无缝切换。 注解 Annotations通常，Xml文件用于配置特定组件，或映射两种不同规格的组件。 在我们的例子中，我们必须在框架中单独维护xml。 这意味着在编写映射xml文件时，我们需要将POJO类属性与mapping.xml文件中的实体标记进行比较。 这是解决方案:在类定义中，我们可以使用注释编写配置部分。 注释用于类，属性和方法。 注释以“@”符号开头。 在声明类，属性或方法之前声明注释。 JPA的所有注释都在javax.persistence包中定义。 以下是我们的示例中使用的注释列表 注解 描述 @Entity 此批注指定将类声明为实体或表 @Table 此批注指定声明表名。 @Basic 此批注明确指定非约束字段 @Embedded 此批注指定类或实体的属性，该实体的可嵌入类的值实例。 @Id 此批注指定属性，用于类的标识（表的主键）。 @GeneratedValue 此批注指定了如何初始化标识属性，例如自动，手动或从序列表中获取的值。 @Transient 此批注指定了不持久的属性，即该值永远不会存储到数据库中。 @Column 此批注用于指定持久性属性的列或属性。 @SequenceGenerator 此批注用于定义@GeneratedValue批注中指定的属性的值。 它创建了一个序列。 @TableGenerator 此批注用于指定@GeneratedValue批注中指定的属性的值生成器。 它创建了一个价值生成表。 @AccessType 此类注释用于设置访问类型。 如果设置@AccessType（FIELD），则会发生字段访问。 如果设置@AccessType（PROPERTY），则将进行Property wise评估。 @JoinColumn 此批注用于指定实体关联或实体集合。 这用于多对一和一对多关联。 @UniqueConstraint 此批注用于指定主要或辅助表的字段，唯一约束。 @ColumnResult 此批注使用select子句引用SQL查询中的列的名称。 @ManyToMany 此批注用于定义连接表之间的多对多关系。 @ManyToOne 此批注用于定义连接表之间的多对一关系。 @OneToMany 此批注用于定义连接表之间的一对多关系。 @OneToOne 此批注用于定义连接表之间的一对一关系。 @NamedQueries 此批注用于指定命名查询的列表。 @NamedQuery 此批注用于使用静态名称指定查询。","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"http://visonforcoding.xyz/tags/Java/"}]},{"title":"PHP QA","slug":"php/PHP-QA之PHPStan","date":"2020-09-17T12:44:41.000Z","updated":"2020-09-23T02:05:37.513Z","comments":true,"path":"2020/09/17/php/PHP-QA之PHPStan/","link":"","permalink":"http://visonforcoding.xyz/2020/09/17/php/PHP-QA%E4%B9%8BPHPStan/","excerpt":"写在前面，工作7年，PHP也写了7年了。期间也写一些java和python，也对各语言的特点有一些自己的体会。这次咱们聊聊QA之余也来聊聊PHP语言本身。","text":"写在前面，工作7年，PHP也写了7年了。期间也写一些java和python，也对各语言的特点有一些自己的体会。这次咱们聊聊QA之余也来聊聊PHP语言本身。 来到PHPStan的官网，我看到了一段话。 I really like how much productivity a web developer gains by switching from compiled languages like Java or C# to an interpreted one like PHP. Aside from the dead simple execution model (start, handle one request, and die) and a much shorter feedback loop (no need to wait for the compiler), there’s a healthy ecosystem of open-source frameworks and libraries to help developers with their everyday tasks. Because of these reasons, PHP is the most popular language for web development by far. 大意是作者很乐意看到web开发者们从C#或Java这些编译性语言里切换到解释语言。除了简单的执行模型（启动，处理一个请求和终止）和较短的反馈周期（无需等待编译）之外，还有一个健康的开源框架和库生态系统可帮助开发人员完成日常工作任务。由于这些原因，PHP是迄今为止最流行的Web开发语言。 这篇文章是作者2016年12月4日写的，说实话对于PHP是迄今为止最流行的Web开发语言这句话我已经开始怀疑了。至少在最近这些年，在国内PHP的市场已经不那么好了。并且我也在趋向从解释性语言向编译语言切换了。但是其中对于解释性语言的优势描述我是非常赞同的，这也是它宝贵的优势。 简单的执行模型 较短的反馈周期 QA之PHPStan言归正传，继续PHPStan 安装composer require --dev phpstan/phpstan运行vendor/bin/phpstan analyse src testsPHPmd~/vendor/bin/phpmd src/Service/OrderService.php text codesize,unusedcode,naming","categories":[],"tags":[{"name":"PHP","slug":"PHP","permalink":"http://visonforcoding.xyz/tags/PHP/"}]},{"title":"vue+vuex+axios+vant+vue-router简单单页登录态demo","slug":"web/vue-vuex-axios-vant-vue-router简单单页登录态demo","date":"2020-09-15T10:12:12.000Z","updated":"2020-09-15T10:26:52.452Z","comments":true,"path":"2020/09/15/web/vue-vuex-axios-vant-vue-router简单单页登录态demo/","link":"","permalink":"http://visonforcoding.xyz/2020/09/15/web/vue-vuex-axios-vant-vue-router%E7%AE%80%E5%8D%95%E5%8D%95%E9%A1%B5%E7%99%BB%E5%BD%95%E6%80%81demo/","excerpt":"","text":"创建vant项目# 安装 Vue Cli npm install -g @vue/cli # 创建一个项目 vue create hello-world # 创建完成后，可以通过命令打开图形化界面，如下图所示 vue ui # 或者 通过 yarn 安装 yarn add vant 在图形化界面中，点击依赖 -&gt; 安装依赖，然后将 vant 添加到依赖中即可。 vue-routeryarn add vue-router &lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;van-nav-bar title=&quot;标题&quot; left-text=&quot;返回&quot; right-text=&quot;按钮&quot; left-arrow @click-left=&quot;onClickLeft&quot; @click-right=&quot;onClickRight&quot; /&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;van-tabbar v-model=&quot;active&quot;&gt; &lt;van-tabbar-item icon=&quot;home-o&quot; to=&quot;/&quot;&gt;主页&lt;/van-tabbar-item&gt; &lt;van-tabbar-item icon=&quot;search&quot;&gt;标签&lt;/van-tabbar-item&gt; &lt;van-tabbar-item icon=&quot;friends-o&quot;&gt;标签&lt;/van-tabbar-item&gt; &lt;van-tabbar-item icon=&quot;user-o&quot; to=&quot;/user/detail&quot;&gt;我的&lt;/van-tabbar-item&gt; &lt;/van-tabbar&gt; &lt;/div&gt; &lt;/template&gt;&lt;template&gt; &lt;div id=&quot;app&quot;&gt; &lt;van-nav-bar title=&quot;标题&quot; left-text=&quot;返回&quot; right-text=&quot;按钮&quot; left-arrow @click-left=&quot;onClickLeft&quot; @click-right=&quot;onClickRight&quot; /&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;van-tabbar v-model=&quot;active&quot;&gt; &lt;van-tabbar-item icon=&quot;home-o&quot; to=&quot;/&quot;&gt;主页&lt;/van-tabbar-item&gt; &lt;van-tabbar-item icon=&quot;search&quot;&gt;标签&lt;/van-tabbar-item&gt; &lt;van-tabbar-item icon=&quot;friends-o&quot;&gt;标签&lt;/van-tabbar-item&gt; &lt;van-tabbar-item icon=&quot;user-o&quot; to=&quot;/user/detail&quot;&gt;我的&lt;/van-tabbar-item&gt; &lt;/van-tabbar&gt; &lt;/div&gt; &lt;/template&gt; 路由配置和登录态控制 import Vue from &#39;vue&#39; import VueRouter from &#39;vue-router&#39; // import store from &#39;@/store&#39; // import layout from &#39;@/layout/layout&#39; Vue.use(VueRouter) const routes = [ &#123; path: &#39;/&#39;, name: &#39;home&#39;, component: () =&gt; import(&quot;@/views/Home&quot;) &#125;, &#123; path: &#39;/user/detail&#39;, name: &#39;user_detail&#39;, meta:&#123; requireLogin:true &#125;, component: () =&gt; import(&quot;@/views/User/detail.vue&quot;) &#125;, &#123; path: &#39;/login&#39;, name: &#39;login&#39;, meta:&#123; requireLogin:false &#125;, component: () =&gt; import(&quot;@/views/Login/login.vue&quot;) &#125;, ] const router = new VueRouter(&#123; mode: &#39;history&#39;, base: process.env.BASE_URL, routes &#125;) router.beforeEach((to, from, next) =&gt; &#123; const token = sessionStorage.getItem(&#39;token&#39;); // store.getters(&#39;isLogin&#39;) if (to.meta.requireLogin) &#123; //需要检测登录 if (token) &#123; next(); &#125; else &#123; console.log(&#39;前往登录...&#39;) next(&#123; path: &#39;/login&#39; &#125;); &#125; &#125; else &#123; next(); &#125; &#125;) export default router 登录引入axios yarn add axiosimport &#123; login &#125; from &quot;@/api/loginReq&quot;; export default &#123; data() &#123; return &#123; loading: false, loginInfo:&#123; username:&quot;&quot;, pwd:&quot;&quot; &#125; &#125;; &#125;, methods: &#123; onSubmit(values) &#123; this.loading = true; login(this.loginInfo).then((response) =&gt; &#123; console.log(response); if(response.code===0)&#123; sessionStorage.setItem(&#39;token&#39;,response.data.username); &#125; this.$router.push(&#39;/&#39;) &#125;); this.loading = false; &#125;, &#125; &#125;","categories":[],"tags":[{"name":"web","slug":"web","permalink":"http://visonforcoding.xyz/tags/web/"}]},{"title":"spring-boot validation数据验证","slug":"java/spring-boot-validation数据验证","date":"2020-09-14T14:40:18.000Z","updated":"2020-09-15T10:10:30.245Z","comments":true,"path":"2020/09/14/java/spring-boot-validation数据验证/","link":"","permalink":"http://visonforcoding.xyz/2020/09/14/java/spring-boot-validation%E6%95%B0%E6%8D%AE%E9%AA%8C%E8%AF%81/","excerpt":"做业务处理，不可避免的要对参数进行校验，一套完整规范的校验体系可以提高不少的效率。 在写了PHP、java、python 等编程语言之后，我发现java的优势就是它的规范、它的严谨。在jsr之下建立各种场景的标准，所有人都在这套规范下拓展、迭代、升级。最终这套体系变得越来越完美、符合体系的生态产品也越来越多。 这大概就是java最强之处吧。 本节介绍下spring-boot的验证，它也是基于jsr的validation之下。","text":"做业务处理，不可避免的要对参数进行校验，一套完整规范的校验体系可以提高不少的效率。 在写了PHP、java、python 等编程语言之后，我发现java的优势就是它的规范、它的严谨。在jsr之下建立各种场景的标准，所有人都在这套规范下拓展、迭代、升级。最终这套体系变得越来越完美、符合体系的生态产品也越来越多。 这大概就是java最强之处吧。 本节介绍下spring-boot的验证，它也是基于jsr的validation之下。 依赖 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;javax.validation&lt;/groupId&gt; &lt;artifactId&gt;validation-api&lt;/artifactId&gt; &lt;version&gt;2.0.1.Final&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt; &lt;/dependency&gt; javax.validation 正是 jsr的规范。 定义验证规则 @NotBlank(message = &quot;用户名不可为空&quot;) @NotNull(message = &quot;不可为空&quot;) private String username; @NotBlank(message = &quot;密码不可为空&quot;) @NotNull(message = &quot;密码不可为空&quot;) private String pwd; controller使用 public Response login(@Valid @RequestBody LoginInfo loginInfo, HttpServletRequest request, HttpSession session) &#123; &#125; 这里要对@Valid 进行使用 全局处理 @RestControllerAdvice public class ControllerAdvice &#123; /** * ConstraintViolationException */ @ExceptionHandler(MethodArgumentNotValidException.class) public Response handleConstraintViolationException(MethodArgumentNotValidException ex) &#123; Map&lt;String, String&gt; errors = new HashMap&lt;&gt;(); ex.getBindingResult().getAllErrors().forEach((error) -&gt; &#123; String fieldName = ((FieldError) error).getField(); System.out.println(fieldName); String errorMessage = error.getDefaultMessage(); errors.put(fieldName, errorMessage); System.out.println(errorMessage); &#125;); return new Response(ResponseCode.parametrErrror, &quot;参数错误&quot;, errors); &#125; &#125; 由于使用@Valid对参数进行校验之后，如果有校验不通过会抛出一个MethodArgumentNotValidException异常。全局进行捕获之后可以全局处理参数不正确的情况。 参考https://www.cnblogs.com/fqybzhangji/p/10384347.html","categories":[],"tags":[{"name":"spring-boot","slug":"spring-boot","permalink":"http://visonforcoding.xyz/tags/spring-boot/"}]},{"title":"IOC和spring对它的实现","slug":"java/IOC和spring对它的实现","date":"2020-09-09T13:10:50.000Z","updated":"2020-09-17T12:46:06.495Z","comments":true,"path":"2020/09/09/java/IOC和spring对它的实现/","link":"","permalink":"http://visonforcoding.xyz/2020/09/09/java/IOC%E5%92%8Cspring%E5%AF%B9%E5%AE%83%E7%9A%84%E5%AE%9E%E7%8E%B0/","excerpt":"","text":"IOS概述https://www.cnblogs.com/DebugLZQ/archive/2013/06/05/3107957.html 这篇文章已经讲的很好。 我做下总结。 面向对象编程的世界，程序之间的耦合不可避免，而且会使得系统变得难以维护 IOC就是为了降低这种耦合 IOS也不是完美的，所有事情都有优缺点 IOC就是为了把原本互相之间有耦合在一起，会造成牵一发而动全身的现象。通过容器解耦开,各自能独立运作。 spring的实现org.springframework.beans 和org.springframework.context 包是Spring Framework 的IoC 容器的基础。 BeanFactory 接口提供高级的配置机制，可以管理任意类型的对象。 ApplicationContext 是BeanFactory 的子接口。 它添加了和Spring 的AOP 特性很简便的整合； 消息资源处理（用于国际化i18n），事件发布； 应用层特定的上下文， 比如用于Web 应用程序的WebApplicationContext。 总之，BeanFactory 提供了配置框架和基本功能，而ApplicationContext 添加了更多企业级开发特定的功能。","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"php编译参数详解","slug":"php/php编译参数详解","date":"2020-09-03T02:19:37.000Z","updated":"2021-08-23T08:57:53.302Z","comments":true,"path":"2020/09/03/php/php编译参数详解/","link":"","permalink":"http://visonforcoding.xyz/2020/09/03/php/php%E7%BC%96%E8%AF%91%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/","excerpt":"尽管经历了N次的手动编译，你可能还是不知道哪些编译参数需要哪些不需要","text":"尽管经历了N次的手动编译，你可能还是不知道哪些编译参数需要哪些不需要 help执行帮助命令查看编译配置帮助 ./configure --help=short得到结果 Optional Features and Packages: --disable-option-checking ignore unrecognized --enable/--with options --disable-FEATURE do not include FEATURE (same as --enable-FEATURE=no) --enable-FEATURE[=ARG] include FEATURE [ARG=yes] --with-PACKAGE[=ARG] use PACKAGE [ARG=yes] --without-PACKAGE do not use PACKAGE (same as --with-PACKAGE=no) --with-libdir=NAME Look for libraries in .../NAME rather than .../lib --disable-rpath Disable passing additional runtime library search paths --enable-re2c-cgoto Enable -g flag to re2c to use computed goto gcc extension --disable-gcc-global-regs whether to enable GCC global register variables SAPI modules: --with-apxs2=FILE Build shared Apache 2.0 Handler module. FILE is the optional pathname to the Apache apxs tool apxs --disable-cli Disable building CLI version of PHP (this forces --without-pear) --enable-embed=TYPE EXPERIMENTAL: Enable building of embedded SAPI library TYPE is either &#39;shared&#39; or &#39;static&#39;. TYPE=shared --enable-fpm Enable building of the fpm SAPI executable fastcgi进程管理,这个应该必不可少 --with-fpm-user=USER Set the user for php-fpm to run as. (default: nobody) --with-fpm-group=GRP Set the group for php-fpm to run as. For a system user, this should usually be set to match the fpm username (default: nobody) --with-fpm-systemd Activate systemd integration --with-fpm-acl Use POSIX Access Control Lists --with-litespeed Build PHP as litespeed module --enable-phpdbg Build phpdbg --enable-phpdbg-webhelper Build phpdbg web SAPI support --enable-phpdbg-debug Build phpdbg in debug mode --enable-phpdbg-readline Enable readline support in phpdbg (depends on static ext/readline) --disable-cgi Disable building CGI version of PHP 禁用cgi --with-valgrind=DIR Enable valgrind support General settings: --enable-gcov Enable GCOV code coverage (requires LTP) - FOR DEVELOPERS ONLY!! --enable-debug Compile with debugging symbols --with-layout=TYPE Set how installed files will be laid out. Type can be either PHP or GNU [PHP] --with-config-file-path=PATH Set the path in which to look for php.ini [PREFIX/lib] --with-config-file-scan-dir=PATH Set the path where to scan for configuration files --enable-sigchild Enable PHP&#39;s own SIGCHLD handler --enable-libgcc Enable explicitly linking against libgcc --disable-short-tags Disable the short-form &lt;? start tag by default --enable-dmalloc Enable dmalloc --disable-ipv6 Disable IPv6 support --enable-dtrace Enable DTrace support --enable-fd-setsize Set size of descriptor sets Extensions: --with-EXTENSION=shared[,PATH] NOTE: Not all extensions can be build as &#39;shared&#39;. Example: --with-foobar=shared,/usr/local/foobar/ o Builds the foobar extension as shared extension. o foobar package install prefix is /usr/local/foobar/ --disable-all Disable all extensions which are enabled by default --disable-libxml Disable LIBXML support --with-libxml-dir=DIR LIBXML: libxml2 install prefix --with-openssl=DIR Include OpenSSL support (requires OpenSSL &gt;= 1.0.1) --with-kerberos=DIR OPENSSL: Include Kerberos support --with-system-ciphers OPENSSL: Use system default cipher list instead of hardcoded value --with-pcre-regex=DIR Include Perl Compatible Regular Expressions support. DIR is the PCRE install prefix BUNDLED --with-pcre-jit Enable PCRE JIT functionality (BUNDLED only) --with-pcre-valgrind=DIR Enable PCRE valgrind support. Developers only! --without-sqlite3=DIR Do not include SQLite3 support. DIR is the prefix to SQLite3 installation directory. --with-zlib=DIR Include ZLIB support (requires zlib &gt;= 1.2.0.4) --with-zlib-dir=&lt;DIR&gt; Define the location of zlib install directory --enable-bcmath Enable bc style precision math functions --with-bz2=DIR Include BZip2 support --enable-calendar Enable support for calendar conversion --disable-ctype Disable ctype functions --with-curl=DIR Include cURL support --enable-dba Build DBA with bundled modules. To build shared DBA extension use --enable-dba=shared --with-qdbm=DIR DBA: QDBM support --with-gdbm=DIR DBA: GDBM support --with-ndbm=DIR DBA: NDBM support --with-db4=DIR DBA: Oracle Berkeley DB 4.x or 5.x support --with-db3=DIR DBA: Oracle Berkeley DB 3.x support --with-db2=DIR DBA: Oracle Berkeley DB 2.x support --with-db1=DIR DBA: Oracle Berkeley DB 1.x support/emulation --with-dbm=DIR DBA: DBM support --with-tcadb=DIR DBA: Tokyo Cabinet abstract DB support --with-lmdb=DIR DBA: Lightning memory-mapped database support --without-cdb=DIR DBA: CDB support (bundled) --disable-inifile DBA: INI support (bundled) --disable-flatfile DBA: FlatFile support (bundled) --disable-dom Disable DOM support --with-libxml-dir=DIR DOM: libxml2 install prefix --with-enchant=DIR Include enchant support. GNU Aspell version 1.1.3 or higher required. --enable-exif Enable EXIF (metadata from images) support --disable-fileinfo Disable fileinfo support --disable-filter Disable input filter support --with-pcre-dir FILTER: pcre install prefix --enable-ftp Enable FTP support --with-openssl-dir=DIR FTP: openssl install prefix --with-gd=DIR Include GD support. DIR is the GD library base install directory BUNDLED --with-webp-dir=DIR GD: Set the path to libwebp install prefix --with-jpeg-dir=DIR GD: Set the path to libjpeg install prefix --with-png-dir=DIR GD: Set the path to libpng install prefix --with-zlib-dir=DIR GD: Set the path to libz install prefix --with-xpm-dir=DIR GD: Set the path to libXpm install prefix --with-freetype-dir=DIR GD: Set the path to FreeType 2 install prefix --enable-gd-jis-conv GD: Enable JIS-mapped Japanese font support --with-gettext=DIR Include GNU gettext support --with-gmp=DIR Include GNU MP support --with-mhash=DIR Include mhash support --disable-hash Disable hash support --without-iconv=DIR Exclude iconv support --with-imap=DIR Include IMAP support. DIR is the c-client install prefix --with-kerberos=DIR IMAP: Include Kerberos support. DIR is the Kerberos install prefix --with-imap-ssl=DIR IMAP: Include SSL support. DIR is the OpenSSL install prefix --with-interbase=DIR Include Firebird support. DIR is the Firebird base install directory /opt/firebird --enable-intl Enable internationalization support --with-icu-dir=DIR Specify where ICU libraries and headers can be found --disable-json Disable JavaScript Object Serialization support --with-ldap=DIR Include LDAP support --with-ldap-sasl=DIR LDAP: Include Cyrus SASL support --enable-mbstring Enable multibyte string support --disable-mbregex MBSTRING: Disable multibyte regex support --disable-mbregex-backtrack MBSTRING: Disable multibyte regex backtrack check --with-libmbfl=DIR MBSTRING: Use external libmbfl. DIR is the libmbfl base install directory BUNDLED --with-onig=DIR MBSTRING: Use external oniguruma. DIR is the oniguruma install prefix. If DIR is not set, the bundled oniguruma will be used --with-mysqli=FILE Include MySQLi support. FILE is the path to mysql_config. If no value or mysqlnd is passed as FILE, the MySQL native driver will be used --enable-embedded-mysqli MYSQLi: Enable embedded support Note: Does not work with MySQL native driver! --with-mysql-sock=SOCKPATH MySQLi/PDO_MYSQL: Location of the MySQL unix socket pointer. If unspecified, the default locations are searched --with-oci8=DIR Include Oracle Database OCI8 support. DIR defaults to $ORACLE_HOME. Use --with-oci8=instantclient,/path/to/instant/client/lib to use an Oracle Instant Client installation --with-odbcver=HEX Force support for the passed ODBC version. A hex number is expected, default 0x0350. Use the special value of 0 to prevent an explicit ODBCVER to be defined. --with-adabas=DIR Include Adabas D support /usr/local --with-sapdb=DIR Include SAP DB support /usr/local --with-solid=DIR Include Solid support /usr/local/solid --with-ibm-db2=DIR Include IBM DB2 support /home/db2inst1/sqllib --with-ODBCRouter=DIR Include ODBCRouter.com support /usr --with-empress=DIR Include Empress support \\$EMPRESSPATH (Empress Version &gt;= 8.60 required) --with-empress-bcs=DIR Include Empress Local Access support \\$EMPRESSPATH (Empress Version &gt;= 8.60 required) --with-birdstep=DIR Include Birdstep support /usr/local/birdstep --with-custom-odbc=DIR Include user defined ODBC support. DIR is ODBC install base directory /usr/local. Make sure to define CUSTOM_ODBC_LIBS and have some odbc.h in your include dirs. f.e. you should define following for Sybase SQL Anywhere 5.5.00 on QNX, prior to running this configure script: CPPFLAGS=\\&quot;-DODBC_QNX -DSQLANY_BUG\\&quot; LDFLAGS=-lunix CUSTOM_ODBC_LIBS=\\&quot;-ldblib -lodbc\\&quot; --with-iodbc=DIR Include iODBC support /usr/local --with-esoob=DIR Include Easysoft OOB support /usr/local/easysoft/oob/client --with-unixODBC=DIR Include unixODBC support /usr/local --with-dbmaker=DIR Include DBMaker support --disable-opcache Disable Zend OPcache support --disable-opcache-file Disable file based caching --disable-huge-code-pages Disable copying PHP CODE pages into HUGE PAGES --enable-pcntl Enable pcntl support (CLI/CGI only) --disable-pdo Disable PHP Data Objects support --with-pdo-dblib=DIR PDO: DBLIB-DB support. DIR is the FreeTDS home directory --with-pdo-firebird=DIR PDO: Firebird support. DIR is the Firebird base install directory /opt/firebird --with-pdo-mysql=DIR PDO: MySQL support. DIR is the MySQL base directory If no value or mysqlnd is passed as DIR, the MySQL native driver will be used --with-zlib-dir=DIR PDO_MySQL: Set the path to libz install prefix --with-pdo-oci=DIR PDO: Oracle OCI support. DIR defaults to $ORACLE_HOME. Use --with-pdo-oci=instantclient,/path/to/instant/client/lib for an Oracle Instant Client installation. --with-pdo-odbc=flavour,dir PDO: Support for &#39;flavour&#39; ODBC driver. include and lib dirs are looked for under &#39;dir&#39;. &#39;flavour&#39; can be one of: ibm-db2, iODBC, unixODBC, generic If &#39;,dir&#39; part is omitted, default for the flavour you have selected will be used. e.g.: --with-pdo-odbc=unixODBC will check for unixODBC under /usr/local. You may attempt to use an otherwise unsupported driver using the \\&quot;generic\\&quot; flavour. The syntax for generic ODBC support is: --with-pdo-odbc=generic,dir,libname,ldflags,cflags When built as &#39;shared&#39; the extension filename is always pdo_odbc.so --with-pdo-pgsql=DIR PDO: PostgreSQL support. DIR is the PostgreSQL base install directory or the path to pg_config --without-pdo-sqlite=DIR PDO: sqlite 3 support. DIR is the sqlite base install directory BUNDLED --with-pgsql=DIR Include PostgreSQL support. DIR is the PostgreSQL base install directory or the path to pg_config --disable-phar Disable phar support --disable-posix Disable POSIX-like functions --with-pspell=DIR Include PSPELL support. GNU Aspell version 0.50.0 or higher required --with-libedit=DIR Include libedit readline replacement (CLI/CGI only) --with-readline=DIR Include readline support (CLI/CGI only) --with-recode=DIR Include recode support --disable-session Disable session support --with-mm=DIR SESSION: Include mm support for session storage --enable-shmop Enable shmop support --disable-simplexml Disable SimpleXML support --with-libxml-dir=DIR SimpleXML: libxml2 install prefix --with-snmp=DIR Include SNMP support --with-openssl-dir=DIR SNMP: openssl install prefix --enable-soap Enable SOAP support --with-libxml-dir=DIR SOAP: libxml2 install prefix --enable-sockets Enable sockets support --with-sodium=DIR Include sodium support --with-password-argon2=DIR Include Argon2 support in password_*. DIR is the Argon2 shared library path] --enable-sysvmsg Enable sysvmsg support --enable-sysvsem Enable System V semaphore support --enable-sysvshm Enable the System V shared memory support --with-tidy=DIR Include TIDY support --disable-tokenizer Disable tokenizer support --enable-wddx Enable WDDX support --with-libxml-dir=DIR WDDX: libxml2 install prefix --with-libexpat-dir=DIR WDDX: libexpat dir for XMLRPC-EPI (deprecated) --disable-xml Disable XML support --with-libxml-dir=DIR XML: libxml2 install prefix --with-libexpat-dir=DIR XML: libexpat install prefix (deprecated) --disable-xmlreader Disable XMLReader support --with-libxml-dir=DIR XMLReader: libxml2 install prefix --with-xmlrpc=DIR Include XMLRPC-EPI support --with-libxml-dir=DIR XMLRPC-EPI: libxml2 install prefix --with-libexpat-dir=DIR XMLRPC-EPI: libexpat dir for XMLRPC-EPI (deprecated) --with-iconv-dir=DIR XMLRPC-EPI: iconv dir for XMLRPC-EPI --disable-xmlwriter Disable XMLWriter support --with-libxml-dir=DIR XMLWriter: libxml2 install prefix --with-xsl=DIR Include XSL support. DIR is the libxslt base install directory (libxslt &gt;= 1.1.0 required) --enable-zend-test Enable zend-test extension --enable-zip Include Zip read/write support --with-zlib-dir=DIR ZIP: Set the path to libz install prefix --with-pcre-dir ZIP: pcre install prefix --with-libzip=DIR ZIP: use libzip --enable-mysqlnd Enable mysqlnd explicitly, will be done implicitly when required by other extensions --disable-mysqlnd-compression-support Disable support for the MySQL compressed protocol in mysqlnd --with-zlib-dir=DIR mysqlnd: Set the path to libz install prefix PEAR: --with-pear=DIR Install PEAR in DIR [PREFIX/lib/php] --without-pear Do not install PEAR Zend: --enable-maintainer-zts Enable thread safety - for code maintainers only!! --disable-inline-optimization If building zend_execute.lo fails, try this switch --disable-zend-signals whether to enable zend signal handling TSRM: --with-tsrm-pth=pth-config Use GNU Pth --with-tsrm-st Use SGI&#39;s State Threads --with-tsrm-pthreads Use POSIX threads (default) Libtool: --enable-shared=PKGS Build shared libraries default=yes --enable-static=PKGS Build static libraries default=yes --enable-fast-install=PKGS Optimize for fast installation default=yes --with-gnu-ld Assume the C compiler uses GNU ld default=no --disable-libtool-lock Avoid locking (might break parallel builds) --with-pic Try to use only PIC/non-PIC objects default=use both --with-tags=TAGS Include additional configurations automatic Some influential environment variables: CC C compiler command CFLAGS C compiler flags LDFLAGS linker flags, e.g. -L&lt;lib dir&gt; if you have libraries in a nonstandard directory &lt;lib dir&gt; LIBS libraries to pass to the linker, e.g. -l&lt;library&gt; CPPFLAGS (Objective) C/C++ preprocessor flags, e.g. -I&lt;include dir&gt; if you have headers in a nonstandard directory &lt;include dir&gt; CPP C preprocessor YACC The `Yet Another Compiler Compiler&#39; implementation to use. Defaults to the first program found out of: `bison -y&#39;, `byacc&#39;, `yacc&#39;. YFLAGS The list of arguments that will be passed by default to $YACC. This script will default YFLAGS to the empty string to avoid a default value of `-d&#39; given by some make applications. CXX C++ compiler command CXXFLAGS C++ compiler flags CXXCPP C++ preprocessor Use these variables to override the choices made by `configure&#39; or to help it to find libraries and programs with nonstandard names/locations. 默认拓展当不配置任何参数时，它默认会有哪些拓展呢？ php -m[PHP Modules] Core ctype date dom fileinfo filter hash iconv json libxml pcre PDO pdo_sqlite Phar posix Reflection session SimpleXML SPL sqlite3 standard tokenizer xml xmlreader xmlwriter [Zend Modules]此时你会发现连php-fpm都没有 常用配置依赖安装yum install -y libxml2-devel openssl-devel./configure --enable-fpm --enable-bcmath --with-openssl \\ --enable-mbstring --with-mysqli --enable-mysqlnd编译安装make &amp;&amp; make install启动查看ini配置php -ini | grep &#39;ini&#39;Configuration File (php.ini) Path =&gt; /usr/local/lib Loaded Configuration File =&gt; /usr/local/lib/php.ini Scan this dir for additional .ini files =&gt; (none) Additional .ini files parsed =&gt; (none) user_ini.cache_ttl =&gt; 300 =&gt; 300 user_ini.filename =&gt; .user.ini =&gt; .user.ini init_command_executed_count =&gt; 0 init_command_failed_count =&gt; 0 com_init_db =&gt; 0从源代码目录 复制配置文件到Configuration File (php.ini) Path cp php.ini-production /usr/local/lib/php.ini设置服务&amp;开机启动(centos 7+)服务服务脚本到systemd cp sapi/fpm/php-fpm.service /etc/systemd/system/ 查看启动脚本 cat sapi/fpm/php-fpm.service结果 # It&#39;s not recommended to modify this file in-place, because it # will be overwritten during upgrades. If you want to customize, # the best way is to use the &quot;systemctl edit&quot; command. [Unit] Description=The PHP FastCGI Process Manager After=network.target [Service] Type=simple PIDFile=/usr/local/var/run/php-fpm.pid ExecStart=/usr/local/sbin/php-fpm --nodaemonize --fpm-config /usr/local/etc/php-fpm.conf ExecReload=/bin/kill -USR2 $MAINPID PrivateTmp=true [Install] WantedBy=multi-user.target配置cp sapi/fpm/php-fpm.conf /usr/local/etc/php-fpm.conf 修改php-fpm.conf 相应配置使得PIDFile文件位置与php-fpm.service配置的一致。并复制www.conf到对应目录 启动systemctl daemon-reload systemctl start php-fpm.service systemctl status php-fpm.service systemctl enable php-fpm.service","categories":[],"tags":[{"name":"php","slug":"php","permalink":"http://visonforcoding.xyz/tags/php/"}]},{"title":"supervisor使用","slug":"supervisor使用","date":"2020-09-02T02:50:48.000Z","updated":"2020-09-02T03:38:19.316Z","comments":true,"path":"2020/09/02/supervisor使用/","link":"","permalink":"http://visonforcoding.xyz/2020/09/02/supervisor%E4%BD%BF%E7%94%A8/","excerpt":"作为一款进程管理工具，supervisor普遍用来管理应用的守护进程","text":"作为一款进程管理工具，supervisor普遍用来管理应用的守护进程 安装常规安装的方式有两种,pip安装或发行版安装 以centos 8为pip安装方式为例。 pip安装pip install supervisor 运行配置文件echo_supervisord_conf &gt; /etc/supervisord.conf生成配置文件 配置systemd服务如果是发行版安装，默认会配置好开机启动服务。如果非发行版安装，可以手动配置。 There are user-contributed scripts for various operating systems at: https://github.com/Supervisor/initscripts 注意，事实上github上的脚本有点问题，与实际安装的目录位置不匹配。稍作修改 # supervisord service for systemd (CentOS 7.0+) # by ET-CS (https://github.com/ET-CS) [Unit] Description=Supervisor daemon [Service] Type=forking ExecStart=/usr/local/bin/supervisord ExecStop=/usr/local/bin/supervisorctl $OPTIONS shutdown ExecReload=/usr/local/bin/supervisorctl $OPTIONS reload KillMode=process Restart=on-failure RestartSec=42s [Install] WantedBy=multi-user.target 将此文件为保存为 vim /etc/systemd/system/supervisord.service 启动服务重新读取所有服务项 systemctl daemon-reload启动服务 systemctl start supervisord.service开机启动 systemctl enable supervisord.service使用启用子配置目录vim /etc/supervisord.conf最后2行打开注释并编辑为 [include] files = ./supervisord.d/*.ini重启 systemctl reload supervisord.service # 或者 supervisorctl reload添加项目vim /etc/supervisord.d/glances.ini [program:glances] command=glances --export influxdb -q process_name=%(program_name)s numprocs=1 directory=/tmp umask=022 priority=999 autostart=true autorestart=unexpected startsecs=10 startretries=3 exitcodes=0 stopsignal=TERM stopwaitsecs=10 stopasgroup=false killasgroup=false user=root redirect_stderr=false stdout_logfile=/var/log/glances/glances-out.log stdout_logfile_maxbytes=1MB stdout_logfile_backups=10 stdout_capture_maxbytes=1MB stdout_events_enabled=false stderr_logfile=/var/log/glances/glances-err.log stderr_logfile_maxbytes=1MB stderr_logfile_backups=10 stderr_capture_maxbytes=1MB 注意先建好目录 /var/log/glances 重新读取配置并启用supervisorctl reload supervisorctl start glances可查看运行状态supervisorctl status结果 glances RUNNING pid 46026, uptime 0:05:05","categories":[],"tags":[{"name":"运维","slug":"运维","permalink":"http://visonforcoding.xyz/tags/%E8%BF%90%E7%BB%B4/"}]},{"title":"mysql字符集问题","slug":"mysql字符集问题","date":"2020-09-01T11:01:33.000Z","updated":"2020-09-02T01:27:13.474Z","comments":true,"path":"2020/09/01/mysql字符集问题/","link":"","permalink":"http://visonforcoding.xyz/2020/09/01/mysql%E5%AD%97%E7%AC%A6%E9%9B%86%E9%97%AE%E9%A2%98/","excerpt":"现代产品和国际化产品建议都使用utf8mb4字符集，表情已无处不在🤖🦖。人生苦短建议mb4.","text":"现代产品和国际化产品建议都使用utf8mb4字符集，表情已无处不在🤖🦖。人生苦短建议mb4. mysql 可以设置数据库级别，表级别，列级别 字符集编码；控制粒度依次细化，也就是如果都设置了，列级别优先级最高。 定义数据表结构时建议不要定义列的字符集，以免将来修改变得麻烦。 修改表的字符集修改表的字符集 并刷新之前已存在的数据ALTER table table_name CONVERT to CHARACTER set 新的字符集; 修改表的字符集，但不对之前已存在的数据刷新ALTER table table_name DEFAULT to CHARACTER set 新的字符集; 批量修改SELECT CONCAT( &#39;ALTER TABLE &#39;, TABLE_NAME, &#39; CONVERT TO CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;&#39; ) FROM information_schema.`TABLES` WHERE TABLE_SCHEMA = &#39;DATABASE_NAME&#39;; 得到修改语句，复制出执行语句，进行执行。如果数据库数据较多，将会比较耗时。 如果只是修改默认字符集不修改数据。 SELECT CONCAT( &#39;ALTER TABLE &#39;, TABLE_NAME, &#39; DEFAULT CHARACTER SET utf8mb4 COLLATE utf8mb4_general_ci;&#39; ) FROM information_schema.`TABLES` WHERE TABLE_SCHEMA = &#39;DATABASE_NAME&#39;; 这样执行应该较为安全，也满足一般需求。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://visonforcoding.xyz/tags/mysql/"}]},{"title":"使用openjdk 11","slug":"java/mac下使用openjdk-11","date":"2020-08-27T03:41:07.000Z","updated":"2021-08-23T08:56:21.472Z","comments":true,"path":"2020/08/27/java/mac下使用openjdk-11/","link":"","permalink":"http://visonforcoding.xyz/2020/08/27/java/mac%E4%B8%8B%E4%BD%BF%E7%94%A8openjdk-11/","excerpt":"最近似乎java 8以上的版本都不能从oracle官网下载了，于是就尝试使用open jdk11","text":"最近似乎java 8以上的版本都不能从oracle官网下载了，于是就尝试使用open jdk11 下载可以从 https://mirrors.huaweicloud.com/openjdk/ 下载得到 mac安装sudo mv /Downloads/jdk11 /Library/Java/JavaVirtualMachines/jdk-11.jdklinux配置bash_profile vim ~/.bash_profile JAVA_HOME=&quot;/usr/local/jdk-11.0.2&quot; PATH=$PATH:$HOME/bin:$JAVA_HOME/bin export PATH","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"glances+influxdb+granfana打造服务器监控系统","slug":"glances-influxdb-granfana打造服务器监控系统","date":"2020-08-25T09:56:32.000Z","updated":"2021-08-11T07:10:06.693Z","comments":true,"path":"2020/08/25/glances-influxdb-granfana打造服务器监控系统/","link":"","permalink":"http://visonforcoding.xyz/2020/08/25/glances-influxdb-granfana%E6%89%93%E9%80%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9B%91%E6%8E%A7%E7%B3%BB%E7%BB%9F/","excerpt":"服务监控就是你的眼睛，当你对服务器运行状况一无所知时，你应该感到坐立不安。","text":"服务监控就是你的眼睛，当你对服务器运行状况一无所知时，你应该感到坐立不安。 glances安装glances是由python编写的，因此可以使用pip直接安装 pip3 install glancesinfluxdb安装wget https://dl.influxdata.com/influxdb/releases/influxdb-1.8.2.x86_64.rpm sudo yum localinstall influxdb-1.8.2.x86_64.rpm收集数据到influxdb配置 glances vim /etc/glances/glances.conf [influxdb] # Configuration for the --export influxdb option # https://influxdb.com/ host=localhost port=8086 user=root password=root db=glances prefix=localhost #tags=foo:bar,spam:eggs pip3 install influxdb glances --export influxdb执行 glances --export influxdb 测试下，报错 InfluxDB database &#39;glances&#39; did not exist. Please create it需要新建数据库。 执行shell influx CREATE DATABASE glances #创建数据 SHOW DATABASES # 查看数据库再次执行glances --export influxdb ,可显示如下代表目前一切正常 作为服务运行此时我们需要编写.service脚本作为服务后台运行 [Unit] Description=glances daemon After=network.target influxdb.service [Service] User=root Group=root ExecStart=/usr/local/bin/glances --quiet --export influxdb Type=simple KillMode=process [Install] WantedBy=multi-user.target 命名该文件为glances.service并放到/usr/lib/systemd/system目录下 systemctl start glances 启动 更多的 service脚本编写可参考，http://www.jinbuguo.com/systemd/systemd.service.html granfana安装wget https://dl.grafana.com/oss/release/grafana-7.1.5-1.x86_64.rpm sudo yum install grafana-7.1.5-1.x86_64.rpm启动systemctl daemon-reload systemctl start grafana-server systemctl status grafana-server systemctl enable grafana-server.service docker-granfana安装# docker-compose.yml version: &quot;3.1&quot; services: grafana: image: grafana/grafana:5.1.0 ports: - 3001:3000 environment: - GF_SECURITY_ADMIN_PASSWORD__FILE=/run/secrets/granfa_admin_pwd # 5.2.0之后才可用 nginx配置 server &#123; listen 80; server_name grafana-dev.domain.cn; #charset koi8-r; location / &#123; proxy_pass http://127.0.0.1:3001; proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection &quot;upgrade&quot;; &#125; &#125; 就可以在web上进行访问,初始的账号密码都是admin 配置数据源 docker安装情况应注意docker容器ip 和宿主机ip docker network ls # 查看docker网络 docker network inspect $networkid # 查看具体网络信息 在配置influxdb 数据源时，如果你是用docker安装，需要保持granfana和influxdb是在同一个网段 添加一个看板 grafana 还支持zipkin","categories":[],"tags":[{"name":"devops","slug":"devops","permalink":"http://visonforcoding.xyz/tags/devops/"}]},{"title":"vuetifyjs图标解决方案","slug":"web/vuetifyjs图标解决方案","date":"2020-08-24T02:24:41.000Z","updated":"2021-06-03T06:03:05.620Z","comments":true,"path":"2020/08/24/web/vuetifyjs图标解决方案/","link":"","permalink":"http://visonforcoding.xyz/2020/08/24/web/vuetifyjs%E5%9B%BE%E6%A0%87%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/","excerpt":"vuetifyjs官方提供的方法实际运用当中似乎会存在一些兼容问题，比如使用Font Awesome时有些图标就不会正常显示。","text":"vuetifyjs官方提供的方法实际运用当中似乎会存在一些兼容问题，比如使用Font Awesome时有些图标就不会正常显示。 Font Awesome &lt;!-- 官方 --&gt; &lt;v-icon&gt;fas fa-php&lt;/v-icon&gt; &lt;!-- 替代 --&gt; &lt;i class=&quot;fab fa-php v-icon&quot;&gt;&lt;/i&gt; 有些图标不显示的问题可以使用上述方法替代解决 使用阿里巴巴字体阿里巴巴字体非常多非常庞大，基本想要的都有，而国外的很多不能用。所以可以使用阿里巴巴字体替代。 第一步：拷贝项目下面生成的fontclass代码： 可以在public/index.html 下用 link 标签引入 //at.alicdn.com/t/font_8d5l8fzk5b87iudi.css 第二步：挑选相应图标并获取类名，应用于页面： &lt;i class=&quot;iconfont icon-xxx&quot;&gt;&lt;/i&gt;","categories":[],"tags":[{"name":"web前端","slug":"web前端","permalink":"http://visonforcoding.xyz/tags/web%E5%89%8D%E7%AB%AF/"}]},{"title":"gunicorn+flask_rest构建部署轻量级api服务","slug":"python/gunicorn-flask-rest构建部署轻量级api服务","date":"2020-08-20T07:51:30.000Z","updated":"2020-09-17T12:46:58.342Z","comments":true,"path":"2020/08/20/python/gunicorn-flask-rest构建部署轻量级api服务/","link":"","permalink":"http://visonforcoding.xyz/2020/08/20/python/gunicorn-flask-rest%E6%9E%84%E5%BB%BA%E9%83%A8%E7%BD%B2%E8%BD%BB%E9%87%8F%E7%BA%A7api%E6%9C%8D%E5%8A%A1/","excerpt":"","text":"flask 结构首先简单看看 flask_rest的目录结构。 入口文件#app.py from flask import Flask from flask_restful import Resource, Api from resources.bd import Index,Format from flask_cors import CORS # from common import config app = Flask(__name__) CORS(app) api = Api(app) api.add_resource(Format, &#39;/bd/format&#39;) # if __name__ == &#39;__main__&#39;: # app.run(debug=True) 如果使用gunicorn启动，则注释掉app.run gunicorn启动配置# config.py import os import gevent.monkey gevent.monkey.patch_all() import multiprocessing debug = True loglevel = &#39;debug&#39; bind = &quot;0.0.0.0:5000&quot; pidfile = &quot;logs/gunicorn.pid&quot; accesslog = &quot;logs/access.log&quot; errorlog = &quot;logs/debug.log&quot; daemon = True # 启动的进程数 workers = multiprocessing.cpu_count() worker_class = &#39;gevent&#39; x_forwarded_for_header = &#39;X-FORWARDED-FOR&#39; 启动python3 -m venv webpj source webpj/bin/activate pip install -r requirements.txt -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com pip install xlrd -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com pip install openpyxl -i http://mirrors.aliyun.com/pypi/simple/ --trusted-host mirrors.aliyun.com gunicorn -c config.py app:app 平滑重启cat logs/gunicorn.pid | xargs kill -HUP","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://visonforcoding.xyz/tags/python/"}]},{"title":"pandas数据快速处理","slug":"pandas数据快速处理","date":"2020-07-31T04:24:15.000Z","updated":"2020-07-31T04:29:28.131Z","comments":true,"path":"2020/07/31/pandas数据快速处理/","link":"","permalink":"http://visonforcoding.xyz/2020/07/31/pandas%E6%95%B0%E6%8D%AE%E5%BF%AB%E9%80%9F%E5%A4%84%E7%90%86/","excerpt":"销售同事拿到一份数据，但是数据导出列是json,我顺手就帮他处理了下。不得不说 pandas在处理这类问题还是非常效率高的.","text":"销售同事拿到一份数据，但是数据导出列是json,我顺手就帮他处理了下。不得不说 pandas在处理这类问题还是非常效率高的. import pandas import json data = pandas.read_excel(&#39;data.xlsx&#39;) address = data[&#39;address&#39;].values.tolist() ordertime_list = data[&#39;order_datetime&#39;].values.tolist() address_new_list = [] for ad in address: addressJson = json.loads(ad) address_new_list.append(addressJson[0]) for ad in address_new_list: for t in ordertime_list: ad[&#39;order_time&#39;] = t df = pandas.DataFrame.from_records(address_new_list) df.to_excel(&#39;new_data.xlsx&#39;)","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://visonforcoding.xyz/tags/python/"}]},{"title":"php生态之性能分析","slug":"php/php生态之性能分析","date":"2020-07-23T07:00:58.000Z","updated":"2021-08-23T08:57:56.336Z","comments":true,"path":"2020/07/23/php/php生态之性能分析/","link":"","permalink":"http://visonforcoding.xyz/2020/07/23/php/php%E7%94%9F%E6%80%81%E4%B9%8B%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/","excerpt":"一般情况下我们并不会太关注PHP的执行效率，因为一般而言他都表现正常满足需求。但当真正遇到问题的时候，我们需要有分析性能在哪丢失的能力。","text":"一般情况下我们并不会太关注PHP的执行效率，因为一般而言他都表现正常满足需求。但当真正遇到问题的时候，我们需要有分析性能在哪丢失的能力。 xhprof正是这样的工具。但是由于年久失修，目前已经不支持PHP7 . 不过，好在还有非官方商业组织开源了PHP7版本,tideways-xhprof。 官网 https://tideways.com/profiler/xhprof-for-php7 安装git clone &quot;https://github.com/tideways/php-xhprof-extension.git&quot; cd php-xhprof-extension phpize ./configure make sudo make install 配置好ini，重启查看下php -m 图形化tideways-xhprof 可以将分析出方法调用、方法调用过程和性能消耗数据。 tideways-xhprof 本身还提供商业化服务，有着比较好的体验。不过也同时有开源的图形化工具。比较好的是xhgui和他配套的是perftools/php-profiler.看了下作者，还是markstory，cakephp的作者，几年前使用cakephp的时候，还有过交流。 xgui安装可以选择源码部署，也可以选择docker部署。方便点选择使用docker。 Clone or download xhgui from GitHub. Startup the containers: docker-compose up -d Open your browser at http://xhgui.127.0.0.1.xip.io:8142 or just http://localhost:8142 php-profiler使用官方github上写几种接入方式，我推荐用注册shutdown方式，正在对项目代码无入侵。保存过程在shutdown之后。 $profiler = new \\Xhgui\\Profiler\\Profiler($config); // The profiler itself checks whether it should be enabled // for request (executes lambda function from config) $profiler-&gt;enable(); // shutdown handler collects and stores the data. $profiler-&gt;registerShutdownHandler(); 上面的$config，在使用非文件存储的时候要注意不要安装官方配置来，官方配置目前存在一点问题，新配置会不生效。我看了源码，并且提交了PR。 // &#39;db.host&#39; =&gt; &#39;mongodb://127.0.0.1:27018&#39;, // &#39;db.db&#39; =&gt; &#39;xhprof&#39;, &#39;save.handler.mongodb&#39; =&gt; array( &#39;dsn&#39; =&gt; &#39;mongodb://127.0.0.1:27018&#39;, &#39;database&#39; =&gt; &#39;xhprof&#39;, // Allows you to pass additional options like replicaSet to MongoClient. // &#39;username&#39;, &#39;password&#39; and &#39;db&#39; (where the user is added) &#39;options&#39; =&gt; array(), ), 注释部分才有效. 默认配置&lt;?php /** * Default configuration for Xhgui */ $mongoUri = getenv(&#39;XHGUI_MONGO_URI&#39;) ?: &#39;127.0.0.1:27017&#39;; $mongoUri = str_replace(&#39;mongodb://&#39;, &#39;&#39;, $mongoUri); $mongoDb = getenv(&#39;XHGUI_MONGO_DB&#39;) ?: &#39;xhprof&#39;; return array( &#39;debug&#39; =&gt; false, &#39;mode&#39; =&gt; &#39;development&#39;, // Can be mongodb, file or upload. // For file // //&#39;save.handler&#39; =&gt; &#39;file&#39;, //&#39;save.handler.filename&#39; =&gt; dirname(__DIR__) . &#39;/cache/&#39; . &#39;xhgui.data.&#39; . microtime(true) . &#39;_&#39; . substr(md5($url), 0, 6), // For upload // // Saving profile data by upload is only recommended with HTTPS // endpoints that have IP whitelists applied. // // The timeout option is in seconds and defaults to 3 if unspecified. // //&#39;save.handler&#39; =&gt; &#39;upload&#39;, //&#39;save.handler.upload.uri&#39; =&gt; &#39;https://example.com/run/import&#39;, //&#39;save.handler.upload.timeout&#39; =&gt; 3, // For MongoDB &#39;save.handler&#39; =&gt; &#39;mongodb&#39;, &#39;db.host&#39; =&gt; sprintf(&#39;mongodb://%s&#39;, $mongoUri), &#39;db.db&#39; =&gt; $mongoDb, &#39;pdo&#39; =&gt; array( &#39;dsn&#39; =&gt; &#39;sqlite:/tmp/xhgui.sqlite3&#39;, &#39;user&#39; =&gt; null, &#39;pass&#39; =&gt; null, &#39;table&#39; =&gt; &#39;results&#39; ), // Allows you to pass additional options like replicaSet to MongoClient. // &#39;username&#39;, &#39;password&#39; and &#39;db&#39; (where the user is added) &#39;db.options&#39; =&gt; array(), &#39;templates.path&#39; =&gt; dirname(__DIR__) . &#39;/src/templates&#39;, &#39;date.format&#39; =&gt; &#39;M jS H:i:s&#39;, &#39;detail.count&#39; =&gt; 6, &#39;page.limit&#39; =&gt; 25, // call fastcgi_finish_request() in shutdown handler &#39;fastcgi_finish_request&#39; =&gt; true, // Profile x in 100 requests. (E.g. set XHGUI_PROFLING_RATIO=50 to profile 50% of requests) // You can return true to profile every request. &#39;profiler.enable&#39; =&gt; function() &#123; $ratio = getenv(&#39;XHGUI_PROFILING_RATIO&#39;) ?: 100; return (getenv(&#39;XHGUI_PROFILING&#39;) !== false) &amp;&amp; (mt_rand(1, 100) &lt;= $ratio); &#125;, &#39;profiler.simple_url&#39; =&gt; function($url) &#123; return preg_replace(&#39;/\\=\\d+/&#39;, &#39;&#39;, $url); &#125;, //&#39;profiler.replace_url&#39; =&gt; function($url) &#123; // return str_replace(&#39;token&#39;, &#39;&#39;, $url); //&#125;, &#39;profiler.options&#39; =&gt; array(), &#39;profiler.skip_built_in&#39; =&gt; false, ); 以上是默认配置 效果 图中可以看到,每次请求的花费时间。 通过观察方法调用次数，可以发现symfony ErrorHandler这个组件方法执行的特别多。 于是我取消了这个组件，发现接口请求时间从113ms直接就降到了71ms. 这就是很直观的性能定位了","categories":[],"tags":[{"name":"php","slug":"php","permalink":"http://visonforcoding.xyz/tags/php/"}]},{"title":"edge使用google theme","slug":"edge使用google-theme","date":"2020-07-10T09:27:30.000Z","updated":"2021-06-03T06:50:01.849Z","comments":true,"path":"2020/07/10/edge使用google-theme/","link":"","permalink":"http://visonforcoding.xyz/2020/07/10/edge%E4%BD%BF%E7%94%A8google-theme/","excerpt":"","text":"用edge打开 edge://flags/#edge-allow-store-extension-themes 改为启用！ 访问 https://chrome.google.com/webstore/category/themes 安装即可啦。","categories":[],"tags":[]},{"title":"kafka搭建和使用(PHP语言版本)","slug":"php/kafka安装和使用-PHP语言版本","date":"2020-07-08T08:13:45.000Z","updated":"2021-08-23T08:57:41.225Z","comments":true,"path":"2020/07/08/php/kafka安装和使用-PHP语言版本/","link":"","permalink":"http://visonforcoding.xyz/2020/07/08/php/kafka%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8-PHP%E8%AF%AD%E8%A8%80%E7%89%88%E6%9C%AC/","excerpt":"首先,安装确实是一个费时费力的事情。这里我们使用docker安装。","text":"首先,安装确实是一个费时费力的事情。这里我们使用docker安装。 docker搭建kafka## docker-compose.yml version: &#39;3.1&#39; services: zookeeper: image: wurstmeister/zookeeper ports: - &quot;2181:2181&quot; kafka: image: wurstmeister/kafka ports: - &quot;9092:9092&quot; environment: KAFKA_ADVERTISED_HOST_NAME: 172.17.0.1 KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181 KAFKA_ADVERTISED_PORT: 9092 更多细节建议访问官方文档查阅。 PHP实现生产者 public function kafka(Request $request) &#123; $faker = Factory::create(&#39;zh_CN&#39;); $message = $faker-&gt;name(); Log::debug(&#39;消息&#39;, [&#39;message&#39; =&gt; $message]); $conf = new Conf(); $conf-&gt;set(&#39;log_level&#39;, (string) LOG_DEBUG); $conf-&gt;set(&#39;debug&#39;, &#39;all&#39;); $conf-&gt;set(&#39;metadata.broker.list&#39;, &#39;127.0.0.1:9092&#39;); $conf-&gt;setDrMsgCb(function ($kafka, $message) &#123; Log::debug(&quot;kafka信息&quot;, [&#39;message&#39; =&gt; var_export($message, true)]); &#125;); $conf-&gt;setErrorCb(function ($kafka, $err, $reason) &#123; Log::debug(&quot;kafka错误&quot;, [&#39;err&#39; =&gt; $err, &#39;reason&#39; =&gt; $reason]); &#125;); $conf-&gt;setLogCb(function ($kafka, $level, $facility, $message) &#123; Log::debug(vsprintf(&quot;Kafka %s: %s (level: %d)\\n&quot;, [$facility, $message, $level])); &#125;); //If you need to produce exactly once and want to keep the original produce order, uncomment the line below //$conf-&gt;set(&#39;enable.idempotence&#39;, &#39;true&#39;); $producer = new Producer($conf); $topic = $producer-&gt;newTopic(&quot;test&quot;); $topic-&gt;produce(RD_KAFKA_PARTITION_UA, 0, $faker-&gt;name()); $producer-&gt;poll(0); $result = $producer-&gt;flush(10000); if (RD_KAFKA_RESP_ERR_NO_ERROR !== $result) &#123; throw new \\RuntimeException(&#39;Was unable to flush, messages might be lost!&#39;); &#125; return new ActionResponse($result); &#125; 消费者public function consume() &#123; $conf = new Conf(); // Configure the group.id. All consumer with the same group.id will consume // different partitions. $conf-&gt;set(&#39;group.id&#39;, &#39;myConsumerGroup&#39;); // Initial list of Kafka brokers $conf-&gt;set(&#39;metadata.broker.list&#39;, &#39;127.0.0.1&#39;); // Set where to start consuming messages when there is no initial offset in // offset store or the desired offset is out of range. // &#39;smallest&#39;: start from the beginning $conf-&gt;set(&#39;auto.offset.reset&#39;, &#39;smallest&#39;); $consumer = new KafkaConsumer($conf); // Subscribe to topic &#39;test&#39; $consumer-&gt;subscribe([&#39;test&#39;]); echo &quot;Waiting for partition assignment... (make take some time when\\n&quot;; echo &quot;quickly re-joining the group after leaving it.)\\n&quot;; while (true) &#123; $message = $consumer-&gt;consume(120 * 1000); switch ($message-&gt;err) &#123; case RD_KAFKA_RESP_ERR_NO_ERROR: $this-&gt;info($message-&gt;payload); break; case RD_KAFKA_RESP_ERR__PARTITION_EOF: echo &quot;No more messages; will wait for more\\n&quot;; break; case RD_KAFKA_RESP_ERR__TIMED_OUT: $this-&gt;info(&quot;Timed out&quot;); break; default: throw new Exception($message-&gt;errstr(), $message-&gt;err); break; &#125; &#125; &#125; 测试生产者是一个restful的api，直接调用会往kafka里写入1个中文姓名的消息。 消费者是一个PHP脚本进程，启动会开始消费kafka消息 php bin/cli.php kafka consume 问题虽然已经搭建了kafka消息中间件,和编写了生产者和消费者.但是关于其中的许多细节还要搞清除。包括: 什么是broken 什么是partition 消息flush是做什么 poll又是做什么 等等更多细节 broken","categories":[],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://visonforcoding.xyz/tags/kafka/"}]},{"title":"一个线上问题引发的对PHP生命周期和SESSION机制思考","slug":"php/一个线上问题引发的对PHP生命周期和SESSION机制思考","date":"2020-07-01T01:59:26.000Z","updated":"2020-09-23T09:13:02.089Z","comments":true,"path":"2020/07/01/php/一个线上问题引发的对PHP生命周期和SESSION机制思考/","link":"","permalink":"http://visonforcoding.xyz/2020/07/01/php/%E4%B8%80%E4%B8%AA%E7%BA%BF%E4%B8%8A%E9%97%AE%E9%A2%98%E5%BC%95%E5%8F%91%E7%9A%84%E5%AF%B9PHP%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F%E5%92%8CSESSION%E6%9C%BA%E5%88%B6%E6%80%9D%E8%80%83/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"PHP生态之自动化测试","slug":"php/PHP生态之自动化测试","date":"2020-07-01T01:58:44.000Z","updated":"2021-08-23T08:57:59.574Z","comments":true,"path":"2020/07/01/php/PHP生态之自动化测试/","link":"","permalink":"http://visonforcoding.xyz/2020/07/01/php/PHP%E7%94%9F%E6%80%81%E4%B9%8B%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95/","excerpt":"PHP TESTING FOR EVERYONE","text":"PHP TESTING FOR EVERYONE 在长久的工作经历中，测试大佬常会在你耳旁嘀咕开发要自测要自测。但是实际上开发往往只会关心当前负责的单元功能的正确与否。繁杂的开发任务当中，还要兼顾所有流程的功能运转可能就没那个精力了，或者说这本身就是测试的工作。在远古时代互联网领域工作还没细分到前端、后端、测试、UI的时候，所有一揽子活都只有一个人做，那就是程序员。 但是如何尽量保证程序返回结果是预期的？ 能否做到每次发布之前自动对程序测试看是否达到预期？这个时候我们可以引入自动化测试。 自动化测试范围 UI测试 接口测试 单元测试 数据测试 其中UI测试和数据测试的自动化可能是最不容易做且效益最小的。这部分可能最好是人为的进行测试效果最好。 在体验了java 的junit之后特别觉得junit的强大,其实PHP也可以做。接下来我们来了解下PHP的测试框架codeception 安装使用installcomposer require &quot;codeception/codeception&quot; --devsetupphp vendor/bin/codecept bootstrap该命令会初始化配置文件和目录 轻量安装Use predefined installation templates for common use cases. Run them instead of bootstrap command. bootstrap会默认初始化所有测试类型所需要的组件，有些你不会用到的类库也会安装。推荐使用轻量安装所用能到的测试类型。 例如你只需要单元测试，则可以 php vendor/bin/codecept init unitsuite配置 初始化之后还要对测试类型进行相应的配置,在tests目录下新建unit的配置 # unit.suite.yml # Codeception Test Suite Configuration # # Suite for unit or integration tests. actor: UnitTester modules: enabled: - Asserts - \\Helper\\Unit step_decorators: ~ codeception单元测试 codeception的单元测试其实也是基于phpunit之上构建的。phpunit的单元测试用例可以之前在codeception上执行。 创建单元测试php vendor/bin/codecept generate:test unit Example执行完会在tests/unit目录里创建测试用例文件 class ExampleTest extends \\Codeception\\Test\\Unit &#123; /** * @var \\UnitTester */ protected $tester; protected function _before() &#123; &#125; protected function _after() &#123; &#125; // tests public function testMe() &#123; &#125; &#125; all public methods with test prefix are tests _before method is executed before each test (like setUp in PHPUnit) _after method is executed after each test (like tearDown in PHPUnit) 运行用例php vendor/bin/codecept run unit ExampleTest如果有目录可以执行到文件 php bin/codecept run unit tests/unit/src/Service/InvoiceServiceTest.php 运行所有单元测试用例 php vendor/bin/codecept run unitclass UserTest extends \\Codeception\\Test\\Unit &#123; public function testValidation() &#123; $user = new User(); $user-&gt;setName(null); $this-&gt;assertFalse($user-&gt;validate([&#39;username&#39;])); $user-&gt;setName(&#39;toolooooongnaaaaaaameeee&#39;); $this-&gt;assertFalse($user-&gt;validate([&#39;username&#39;])); $user-&gt;setName(&#39;davert&#39;); $this-&gt;assertTrue($user-&gt;validate([&#39;username&#39;])); &#125; &#125; 结果 可以统计到所有文件的覆盖率和用例测试结果。 结合git钩子我们可以在每次分支提交时进行自动的用例测试，能一定程度上防止代码更改了而没测试产生非预期的问题。","categories":[],"tags":[{"name":"php","slug":"php","permalink":"http://visonforcoding.xyz/tags/php/"}]},{"title":"intl安装的那些事儿","slug":"php/intl安装的那些事儿","date":"2020-06-19T02:41:25.000Z","updated":"2021-08-23T08:57:37.415Z","comments":true,"path":"2020/06/19/php/intl安装的那些事儿/","link":"","permalink":"http://visonforcoding.xyz/2020/06/19/php/intl%E5%AE%89%E8%A3%85%E7%9A%84%E9%82%A3%E4%BA%9B%E4%BA%8B%E5%84%BF/","excerpt":"被intl折磨的还不够么","text":"被intl折磨的还不够么 To build the extension you need to install the » ICU library, version 4.0.0 or newer is required. As of PHP 7.4.0 ICU 50.1 or newer is required. This extension is bundled with PHP as of PHP version 5.3.0. Alternatively, the PECL version of this extension may be used with all PHP versions greater than 5.2.0 (5.2.4+ recommended). ICU安装现在icu已被放到github，下载建议直接从github下载源码到本地。 https://github.com/unicode-org/icu/releases/tag/release-60-3 下载后编译安装 拓展安装pecl install intl 总会遇到问题,建议用phpize 源码安装。进入源码ext下的intl目录 ./configure --enable-intl --with-php-config=/usr/local/php7/bin/php-config make make install重启php-fpm","categories":[],"tags":[{"name":"php","slug":"php","permalink":"http://visonforcoding.xyz/tags/php/"}]},{"title":"MyBatis Dynamic SQL使用尝试","slug":"java/MyBatis-Dynamic-SQL使用尝试","date":"2020-06-01T15:05:29.000Z","updated":"2021-08-23T08:56:26.089Z","comments":true,"path":"2020/06/01/java/MyBatis-Dynamic-SQL使用尝试/","link":"","permalink":"http://visonforcoding.xyz/2020/06/01/java/MyBatis-Dynamic-SQL%E4%BD%BF%E7%94%A8%E5%B0%9D%E8%AF%95/","excerpt":"首先说明下，我可能是被这个插件的名字给误导了。我原本以为Dynamic SQL是为了解决动态查询场景的。但可能MyBatis Dynamic SQL 并不是来解决这个问题的。 20.06.04更新 打脸了，原来它是支持的，果然是动态sql.并且还真香！","text":"首先说明下，我可能是被这个插件的名字给误导了。我原本以为Dynamic SQL是为了解决动态查询场景的。但可能MyBatis Dynamic SQL 并不是来解决这个问题的。 20.06.04更新 打脸了，原来它是支持的，果然是动态sql.并且还真香！ MyBatis Dynamic SQL官方定义This library is a framework for generating dynamic SQL statements. Think of it as a typesafe SQL templating library, with additional support for MyBatis3 and Spring JDBC Templates. The primary goals of the library are: Typesafe - to the extent possible, the library will ensure that parameter types match the database column types Expressive - statements are built in a way that clearly communicates their meaning (thanks to Hamcrest for some inspiration) Flexible - where clauses can be built using any combination of and, or, and nested conditions Extensible - the library will render statements for MyBatis3, Spring JDBC templates or plain JDBC. It can be extended to generate clauses for other frameworks as well. Custom where conditions can be added easily if none of the built in conditions are sufficient for your needs. Small - the library is a small dependency to add. It has no transitive dependencies. 官方似乎说到这个类库的主要目标是解决类型安全问题。 This library grew out of a desire to create a utility that could be used to improve the code generated by MyBatis Generator, but the library can be used on it’s own with very little setup required. 官方说可以使用MyBatis Generator生成代码文件。 &lt;dependency&gt; &lt;groupId&gt;org.mybatis.dynamic-sql&lt;/groupId&gt; &lt;artifactId&gt;mybatis-dynamic-sql&lt;/artifactId&gt; &lt;version&gt;1.1.4&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;/dependency&gt; MyBatis GeneratorMyBatis Generator may generate: Java or Kotlin classes that match the table structure. This may include: a class to match the primary key of the table (if there is a primary key) a class to match the non-primary key fields of the table (except BLOB fields) a class to include the BLOB fields of a table (if the table has BLOB fields) a class to enable dynamic selects, updates, and deletes MyBatis Generator将会生成下述三个文件： 与表对应的 model 类 Employee.java 定义了表信息和列信息的 support 类 EmployeeDynamicSqlSupport.java 以注解形式实现的 mapper 接口 EmployeeMapper.java Running MyBatis Generator With Maven 配置pom.xml &lt;plugin&gt; &lt;groupId&gt;org.mybatis.generator&lt;/groupId&gt; &lt;artifactId&gt;mybatis-generator-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.4.0&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;Generate MyBatis Artifacts&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;generate&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.20&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;/plugin&gt; 注意mysql-connector-java依赖配置 配置 generatorConfig.xml 在resource中配置生成配置文件generatorConfig.xml &lt;!DOCTYPE generatorConfiguration PUBLIC &quot;-//mybatis.org//DTD MyBatis Generator Configuration 1.0//EN&quot; &quot;http://mybatis.org/dtd/mybatis-generator-config_1_0.dtd&quot;&gt; &lt;generatorConfiguration&gt; &lt;context id=&quot;dsql&quot; targetRuntime=&quot;MyBatis3DynamicSql&quot;&gt; &lt;jdbcConnection driverClass=&quot;com.mysql.jdbc.Driver&quot; connectionURL=&quot;jdbc:mysql://localhost:3306/db_itdoc&quot; userId=&quot;username&quot; password=&quot;password&quot; /&gt; &lt;javaModelGenerator targetPackage=&quot;com.vison.itdoc.entity&quot; targetProject=&quot;src/main/java&quot;/&gt; &lt;javaClientGenerator targetPackage=&quot;com.vison.itdoc.dao&quot; targetProject=&quot;src/main/java&quot;/&gt; &lt;table tableName=&quot;task&quot; /&gt; &lt;/context&gt; &lt;/generatorConfiguration&gt; userId和password分别是数据库用户名和密码 执行生成 $ mvn mybatis-generator:generate 使用MyBatis Dynamic SQL当相应的文件生成之后，这个时候可以直接使用了。 SelectStatementProvider queryCount = select(count()) .from(task) .build() .render(RenderingStrategies.MYBATIS3); Long taskCount = taskMapper.count(queryCount); double total = Math.ceil(taskCount / iPageSize); SelectStatementProvider tasksQuerypProvider = select(createTime).from(task) .orderBy(createTime) .limit(iPageSize).offset(iOffset).build() .render(RenderingStrategy.MYBATIS3); List&lt;Task&gt; tasks = taskMapper.selectMany(tasksQuerypProvider); MyBatis Dynamic SQL非常优雅得sqlbuilder方式,会提示表字段名。 动态sql在这之前mybatis可以使用xml或注解方式进行动态组织sql public class TaskService &#123; public String queryCount(String type, String remark) &#123; return new SQL() &#123; &#123; SELECT(&quot;T.ID&quot;); FROM(&quot;TASK T&quot;); if (type != null) &#123; WHERE(&quot;T.type = #&#123;type&#125;&quot;); &#125; if (remark != null) &#123; WHERE(&quot;T.remark = #&#123;remark&#125;&quot;); &#125; ORDER_BY(&quot;T.create_time&quot;); &#125; &#125;.toString(); &#125; 在mapper上 @SelectProvider(type = TaskService.class, method = &quot;queryCount&quot;) public Object queryCount(String type, String remark); 现在可以换另一种方式 public SelectStatementProvider countTask(Integer typeInteger, String remarkString) &#123; QueryExpressionDSL&lt;SelectModel&gt;.QueryExpressionWhereBuilder builder = select(count()) .from(task).where(); if (typeInteger != null) &#123; builder.and(type, isEqualTo(typeInteger)); &#125; if (remarkString != null) &#123; builder.and(remark, isEqualTo(remarkString)); &#125; return builder.build().render(RenderingStrategy.MYBATIS3); &#125; public SelectStatementProvider search(Object searchObj, Integer iPageSize, Integer iOffset) &#123; QueryExpressionDSL&lt;SelectModel&gt;.QueryExpressionWhereBuilder builder = select(remark, type, createTime, modifyTime) .from(task).where(); builder .orderBy(createTime) .limit(iPageSize).offset(iOffset); return builder.build().render(RenderingStrategy.MYBATIS3); &#125; 从编码感受上，由于根据表结构生成了SqlSupport.任何对表的信息引用都能有提示，包括表名、字段名。 List&lt;Task&gt; tasks = taskMapper.selectMany(taskService.search(null, iPageSize, iOffset)); 调用上面，也无需在mapper上再编写方法，因为已经全部生成了。 参考Mybatis Dynamic SQL - 重新定义 Mybatis 动态 SQL","categories":[],"tags":[{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"}]},{"title":"利用信号控制php常驻进程平滑中断思考","slug":"php/php常驻进程平滑中断","date":"2020-05-30T02:30:49.000Z","updated":"2021-08-23T08:57:50.666Z","comments":true,"path":"2020/05/30/php/php常驻进程平滑中断/","link":"","permalink":"http://visonforcoding.xyz/2020/05/30/php/php%E5%B8%B8%E9%A9%BB%E8%BF%9B%E7%A8%8B%E5%B9%B3%E6%BB%91%E4%B8%AD%E6%96%AD/","excerpt":"很多场景下我们都需要进程程序在后台一直处理任务，比如队列消费。可采用while true的方式让进程常驻按一定的频次执行任务。但是但我们要重启进程或中止进程时，如何保证进程内正在执行的任务执行完毕再中止呢？","text":"很多场景下我们都需要进程程序在后台一直处理任务，比如队列消费。可采用while true的方式让进程常驻按一定的频次执行任务。但是但我们要重启进程或中止进程时，如何保证进程内正在执行的任务执行完毕再中止呢？ 思考一下，可不可以我们通过一种指令告诉进程，”诶，我现在要重启一下，你能把正在做的事情做完了先退出歇会么？” kill命令可以解决这个问题。 再看kill许人肯定会觉得 kill 不就是杀掉进程么？ 我经常用kill -9杀进程。 这么说也没错，不过我们现在可以系统地来看看kill命令. 我们先看下官方的定义,让那个男人来跟我们讲讲。 man shell KILL(1) User Commands KILL(1) NAME kill - terminate a process SYNOPSIS kill [-s signal|-p] [-q sigval] [-a] [--] pid... kill -l [signal] DESCRIPTION The command kill sends the specified signal to the specified process or process group. If no signal is specified, the TERM signal is sent. The TERM signal will kill processes which do not catch this signal. For other processes, it may be necessary to use the KILL (9) signal, since this signal cannot be caught. Most modern shells have a builtin kill function, with a usage rather similar to that of the command described here. The &#39;-a&#39; and &#39;-p&#39; options, and the possibility to specify processes by command name are a local extension. If sig is 0, then no signal is sent, but error checking is still performed. 官方解释kill是用来终止进程的。 kill 发送指定的信号给到进程或进程组。 如果没有指定信号，默认发送TERM信号。 TERM信号将会杀掉进程，当TERM未被捕获的时候。 9信号不能被捕获 谈谈我的理解 kill命令就是用来杀掉进程的 它可以给进程发送一些指令，让程序去捕获做特殊处理。比如上面说到的场景，让程序执行完正在执行的任务，再退出。 验证接下来我们用PHP脚本来验证下上面的理解。我们用pcntl_signal来对信号进行捕获。 class SignalShell extends Shell &#123; private $taskFinish = false; public function __construct() &#123; // pcntl_signal(SIGTERM, [$this, &#39;sig_handler&#39;]); // pcntl_signal(SIGHUP, [$this, &#39;sig_handler&#39;]); pcntl_signal(SIGINT, [$this, &#39;sig_handler&#39;]); // pcntl_signal(SIGQUIT, [$this, &#39;sig_handler&#39;]); pcntl_signal(SIGILL, [$this, &#39;sig_handler&#39;]); pcntl_signal(SIGPIPE, [$this, &#39;sig_handler&#39;]); pcntl_signal(SIGALRM, [$this, &#39;sig_handler&#39;]); pcntl_signal(SIGUSR1, [$this, &#39;sig_handler&#39;]); $this-&gt;info(&quot;注册信号&quot;); &#125; public function task() &#123; while (true &amp;&amp; !$this-&gt;taskFinish) &#123; sleep(10); $this-&gt;info(uniqid()); &#125; &#125; public function sig_handler($signo) &#123; $time = date(&#39;Y-m-d H:i:s&#39;); if ($signo == 14) &#123; //忽略alarm信号 echo $time . &quot; ignore alarm signo[&#123;$signo&#125;]\\r\\n&quot;; &#125; else &#123; echo $time . &quot; exit signo[&#123;$signo&#125;]\\r\\n&quot;; if ($signo == SIGUSR1) &#123; $this-&gt;info(&quot;捕获自定义&quot;); $this-&gt;taskFinish = true; &#125; &#125; &#125; &#125; 代码很简单，就是让脚本每隔10秒输出一个字符串，任务之前对一些信号进行捕获。 分别对进程执行了，kill、kill QUIT、kill HUP 发现进程都会被直接终止。 下面我们开始,对TERM进行捕获。 pcntl_signal(SIGTERM, [$this, &#39;sig_handler&#39;]); 打开注释。 15信号(TERM)被捕获到了，但是进程并没有退出,还再继续执行。 我们再试下USR1信号。 USR1被捕获到了，并且程序立即执行完一次输出退出了。注意我是程序自己控制了,捕获到USR1之后不继续执行循环。 细心的朋友们可能会发现，程序中的sleep被跳过了。 这是什么原因呢? sleep事实上sleep是一个特殊的函数。其实官方文档有解释: sleep在被信号中止时，会返回非0值,非windows下会返回剩余秒数。 让我们来验证下。 while (true &amp;&amp; !$this-&gt;taskFinish) &#123; $res = sleep(10); $this-&gt;info(&quot;sleep返回:&quot;.$res); $this-&gt;info(uniqid()); &#125; 我们记录了sleep执行完的返回值。 发现信号给到时，sleep确实会返回剩余秒数。这就解释了为什么上面看到的sleep被跳过了。 总结 A process can define how to handle incoming POSIX signals. If a process does not define a behaviour for a signal, then the default handler for that signal is being used. The table below lists some default actions for POSIX-compliant UNIX systems, such as FreeBSD, OpenBSD and Linux. kill能给进程发送信号量，告诉进程按什么方式结束。 kill定义的不同信号量，用法不同，但是需要程序自己去处理。它只是定义了目的，但未定义过程和实际结果。 参考https://en.wikipedia.org/wiki/Signal_(IPC)","categories":[],"tags":[{"name":"php linux","slug":"php-linux","permalink":"http://visonforcoding.xyz/tags/php-linux/"}]},{"title":"spring boot分环境自定义配置","slug":"java/spring-boot分环境自定义配置","date":"2020-05-26T05:03:36.000Z","updated":"2021-08-23T08:58:12.152Z","comments":true,"path":"2020/05/26/java/spring-boot分环境自定义配置/","link":"","permalink":"http://visonforcoding.xyz/2020/05/26/java/spring-boot%E5%88%86%E7%8E%AF%E5%A2%83%E8%87%AA%E5%AE%9A%E4%B9%89%E9%85%8D%E7%BD%AE/","excerpt":"在一般规模企业，应当都有测试环境和正式环境区别，或者至少也有开发环境和正式环境。那不同环境必然就会有一些环境依赖的不同，不管是出于安全性考虑还是其他原因导致的。比如数据库配置、OSS账号信息等。那程序当中就需要配置多份配置信息和根据不同环境使用不同配置","text":"在一般规模企业，应当都有测试环境和正式环境区别，或者至少也有开发环境和正式环境。那不同环境必然就会有一些环境依赖的不同，不管是出于安全性考虑还是其他原因导致的。比如数据库配置、OSS账号信息等。那程序当中就需要配置多份配置信息和根据不同环境使用不同配置 分环境配置 # 激活日志环境 spring.profiles.active=prd公共配置还是写在application。相应配置写在-{env} 文件里。 自定义配置获取上面是spring框架所需的默认配置方法，我们通常还需要非常多的自定义配置。比如密码的加盐salt等等，这是项目的自定义配置。 那如果对这些自定义内容进行配置和获取呢。 配置我们依然可以在application.properties进行配置。 例如： app.security.salt=zM2Y&amp;*21.rkJr=11 app.oss.host=http://oss-cn-beijing.aliyuncs.com app.oss.bucket=bucketNanme app.oss.accessKey=accessKey app.oss.accessSecret=accessSecret 获取配置@Service public class OssService &#123; @Value(&quot;$&#123;app.oss.host&#125;&quot;) private String host; @Value(&quot;$&#123;app.oss.accessKey&#125;&quot;) private String accessKeyId; @Value(&quot;$&#123;app.oss.accessSecret&#125;&quot;) private String accessKeySecret; @Value(&quot;$&#123;app.oss.bucket&#125;&quot;) private String bucketName; &#125; 一定要是在spring bean里进行获取，否则无法获取到。 参考 https://docs.spring.io/spring-boot/docs/1.5.22.RELEASE/reference/html/boot-features-external-config.html","categories":[],"tags":[{"name":"java spring-boot","slug":"java-spring-boot","permalink":"http://visonforcoding.xyz/tags/java-spring-boot/"}]},{"title":"mysql单个表的权限控制","slug":"mysql单个表的权限控制","date":"2020-05-08T01:43:39.000Z","updated":"2020-05-26T08:52:13.668Z","comments":true,"path":"2020/05/08/mysql单个表的权限控制/","link":"","permalink":"http://visonforcoding.xyz/2020/05/08/mysql%E5%8D%95%E4%B8%AA%E8%A1%A8%E7%9A%84%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/","excerpt":"在系统开发当中有这样的需求，A系统需要读写B系统的数据库数据,但是某些特殊的表数据只允许读操作。这时候就需要做到表级的权限控制。","text":"在系统开发当中有这样的需求，A系统需要读写B系统的数据库数据,但是某些特殊的表数据只允许读操作。这时候就需要做到表级的权限控制。 revokeMysql本身是支持用revoke进行权限回收操作的。 https://dev.mysql.com/doc/refman/5.6/en/revoke.html REVOKE priv_type [(column_list)] [, priv_type [(column_list)]] ... ON [object_type] priv_level FROM user [, user] ... REVOKE ALL [PRIVILEGES], GRANT OPTION FROM user [, user] ... REVOKE PROXY ON user FROM user [, user] ...从语法当中可以看到还可以做到列级别的控制。 问题mysql&gt; revoke insert,delete,update on db_oms.t_order from &#39;oms_order_ro&#39;@&#39;localhost&#39;; ERROR 1147 (42000): There is no such grant defined for user &#39;oms_order_ro&#39; on host &#39;localhost&#39; on table &#39;t_order&#39;但是事实上，执行的时候会遇到问题。 什么原因呢？ mysql&gt; show grants for oms_order_ro@localhost -&gt; ; +----------------------------------------------------------------------------------+ | Grants for oms_order_ro@localhost | +----------------------------------------------------------------------------------+ | GRANT USAGE ON *.* TO &#39;oms_order_ro&#39;@&#39;localhost&#39; | | GRANT SELECT, INSERT, UPDATE, DELETE ON `db_oms`.* TO &#39;oms_order_ro&#39;@&#39;localhost&#39; | +----------------------------------------------------------------------------------+仔细看下，我们是使用的通配符去进行赋权限。看起来这里mysql还是表现的比较本。认为没有该权限进行回收。 那么正确的做法应该是怎样的呢？ Managing access in mysql can be quite dificult !! Once you gave him database.* you cannot revoke access for an object that is in that class. MySQL doesn’t expand the Hotels.* wildcard to the individual tables The permissions tables store the granted permissions. Therefore, since you didn’t actually grant anything on Hotels.AllHotels , there’s nothing for MySQL to revoke. In this case you need to do it granular form the start ! Remove all privileges on database, table, column levels, etccc. Grant privileges to EACH table, except ‘you choose’.Grant privilege to specified fields in table ‘you choose’. 我们必须要逐个逐个表进行赋权限，然后进行回收。 实际上这么操作虽然能解决问题，但是会带来跟多问题，如果表增加了。你必须再对这个表进行赋权限和回收权限。","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://visonforcoding.xyz/tags/mysql/"}]},{"title":"Selenium自动化测试在页面web性能测试应用的尝试","slug":"Selenium自动化测试在页面web性能测试应有的尝试","date":"2020-05-07T15:26:14.000Z","updated":"2020-05-30T04:27:29.523Z","comments":true,"path":"2020/05/07/Selenium自动化测试在页面web性能测试应有的尝试/","link":"","permalink":"http://visonforcoding.xyz/2020/05/07/Selenium%E8%87%AA%E5%8A%A8%E5%8C%96%E6%B5%8B%E8%AF%95%E5%9C%A8%E9%A1%B5%E9%9D%A2web%E6%80%A7%E8%83%BD%E6%B5%8B%E8%AF%95%E5%BA%94%E6%9C%89%E7%9A%84%E5%B0%9D%E8%AF%95/","excerpt":"对于web测试，我们通常在做的测试都是人工的功能测试。那么少见的自动化测试到底适用哪些场景呢？","text":"对于web测试，我们通常在做的测试都是人工的功能测试。那么少见的自动化测试到底适用哪些场景呢？ 用python进行web自动化测试 前段时间，在客服信息系统进入用户体验阶段时发现内存存在泄露问题。我们花了很多时间去排查原因。经过各种可能的优化方案，结果发现没有实质性的效果，于是我们决定重构。但是如何保证重构方案的可行呢？于是我们用到了python+Selenium 为什么会用到web自动化测试web自动化测试适用场景对于web测试，我们通常在做的测试都是人工的功能测试。那么少见的自动化测试到底适用哪些场景呢？ 回归测试。每一次应用发布，都伴随着一次回归测试。对于重复性的工作，机器显然更适合。 兼容性测试。不管是Web测试，还是App测试，兼容性测试都是必不可少的一环。以Web测试为例，同样的测试用例，需要在不同的浏览器上分别运行一遍，这对测试人员而言不可谓不是一种折磨。 大规模测试。如果一次测试涉及的测试用例过多（比如100+），功能测试难免会有遗漏或者重复，而自动化测试可以轻松确保一个不少，一个也不多。 性能测试 弊端万事皆有利弊，机器的自动化测试没有广泛应用肯定是有原因的。 不低的技术门槛。不论是使用哪种自动化测试框架，对于测试人员而言，都存在一定的技术门槛，一般至少需要学习并掌握一门编程语言。可观的开发成本和维护成本。跟任何程序一样，无论是编写自动化测试脚本，还是在需求变化时修改脚本，都需要花费大量的时间。 需求要稳定。自动化测试的前提是测试用例要稳定，而测试用例稳定的前提是需求要稳定。对于临时的或者说一次性的需求，自动化测试往往是得不偿失的。 应用周期长。应用的生命周期越长，自动化测试节省的时间越多，带来的价值也越大。 性能测试随着web前端技术发展更新越来越迅猛的态势，前端技术和框架层出不穷。但往往我们会在短期内高估技术带来的影响。 所以对于任何一个新的事物，我们采取保守的态度对待可能会少跌入一些幻灭的低谷期。对于新技术做充分的评估测试，可能会让我们少踩一些坑。当然往往这话，都是在事后才会提出来。 为什么可以用自动化测试做性能测试？网上似乎都没有这种先例。我总结以下几个原因： 脚本能强有规律地重复执行操作，而开发或测试自己做这个工作会很繁琐而且出了一步差错就得重来 脚本能将执行操作和数据记录结合起来。而人类执行一次数据记录和动作执行也许没问题，但重复500次或更多而无差错那就困难了。 web自动化测试方法 python+Selenium 跨浏览器支持 puppeteer 专注于chrome airtest 跨平台，安卓、ios、web，web还是用的Selenium 测试结果 执行脚本 脚本运行情况，浏览器在自动进行操作 得出统计结果。我们模拟用户的某个最频繁的操作，发现采用新的方案后内存会在短时间内有效回收。整体上，页面内存会趋于稳定的态势。 遇到的问题动态的ggcode ggcode = prompt(&quot;输入谷歌码: &quot;) 由于登录用的谷歌码是动态的，所以这里只能每次输入进行填充。这里我们引入prompt_toolkit进行终端的交互 获取元素如今的前端项目，由于使用的是数据驱动dom，不是传统的jquery操作，现在基本看不到id class等进行元素定位。现在最方便的做法只能是通过xpath寻找元素。 xpath = &#39;//*[@id=&quot;app&quot;]/div/div[2]/div[1]&#39; element = self.browser.find_element_by_xpath( xpath)由于不是固定id，页面一旦改变xpath很有可能改变，会导致元素找不到。 webdriver进程不退出在使用过程当中发现提供的quit() 方法并不能让进程退出，所以只能自己将进程kill掉。 def close_browser(self): 点击在进行按钮点击的时候，经常会因为页面未加载完等原因导致无法点击。结果就是可能会抛出异常。对于这种情况webdriver本身有提供wait等待。 wait = WebDriverWait(self.browser, 30) element = wait.until(EC.element_to_be_clickable((By.XPATH, xpath))) WebDriverWait 需要设置一个等待时长，不可能无限等待 还有些情况下，是由于需要下拉滚动条才能进行点击。这种情况可以考虑执行js进行点击。 js_click_next_page = &#39;document.querySelector(&quot;body &gt; div.worker-order-search-list &gt; div.content-wrapper &gt; section &gt; ul &gt; li.ivu-page-next&quot;).click()&#39; browser.execute_script(js_click_next_page) 使用webdriver.click还是用js点击？ When Should You Use JavaScript for Clicking?If you are using Selenium for testing an application, my answer to this question is “almost never”. By and large, your Selenium test should reproduce what a user would do with the browser. Taking the example of the drop down menu: a test should click on the button that brings up the drop down first, and then click on the menu item. If there is a problem with the GUI because the button is invisible, or the button fails to show the menu items, or something similar, then your test will fail and you’ll have detected the bug. If you use JavaScript to click around, you won’t be able to detect these bugs through automated testing. 总之还是看你的使用目的，如果自动化测试的目的倾向于测试页面功能。那么建议使用webdriver.click。如果是为了测试性能，那可以进行js点击了。 获取页面内存浏览器的任务管理器可以很容易的看到页面的内存、cpu、网络情况，但是如何获取到记录并统计呢？ 答案是，很可惜现在还没找到。如果有官方办法，请告诉我。 我走了一个其他途径获取，从操作系统层面获取进程。获取一个进程得内存占用是一个简单的事，但是如何知道某个页面的进程id呢。很遗憾的是，webdriver同样没有接口方法提供。于是我只能从webdriver子进程入手，看有没有信息能与page关联上。很遗憾的事，单单从子进程名看与页面毫无关联。所以。。最后，我只能做一个假设，假设浏览器启动类似linux启动。启动的程序是有先后关系的。 def get_page_pid(self, page_num=1): &quot;&quot;&quot;[获取启动页面的进程id,非官方方法,不一定正确。 原理:假设chrome主进程启动子进程是有顺序的,那么打开的页面进程在第4个开始启动] Returns: [type] -- [description] &quot;&quot;&quot; webdriver_pid = self.browser.service.process.pid ps = psutil.Process(webdriver_pid) ps_children = ps.children(True) return ps_children[3+page_num-1].pid 这是一种对项目无侵入的做法，你不需要改动项目代码，就可以对浏览器页面内存进行统计。还有其他做法，可以对项目进行增加内存上报进行统计。但这样的做法同样有弊端： 需要动被测项目，对项目干扰 增加工作量，不光是上报还包括接收上报接口 如果是多iframe页签方式，统计聚合上报将非常繁琐 需要注意的是，统计页面进程方法。得到的数据是整个页面进程所占用的内存，并非页面js占用内存。 统计在统计上，我使用了chartify+pandas,只要传入数据就能快捷地生成图表 def chartArea(self, data, x_column, y_column): &quot;&quot;&quot;[绘制区域图] Arguments: data &#123;[dict]&#125; -- [数据矩阵,拿去构建pandas dataFrame] x_column &#123;[type]&#125; -- [x轴字段] y_column &#123;[type]&#125; -- [y轴字段] &quot;&quot;&quot; data_frame = pd.DataFrame(data) print(data_frame) self.ch.plot.area(data_frame=data_frame, x_column=x_column, y_column=y_column, stacked=True) def show(self, show_type=&#39;html&#39;): self.ch.save(&#39;./output/%s-%s.png&#39; % (self.subtitle, time.strftime(&quot;%Y%m%d%H%M%S&quot;)), &#39;png&#39;) 总结正如前面所说，web自动化测试没有广泛应用肯定是有原因的。但是做为前端问题的论证还是有很大意义。 比如，页面占用内存限制是多少？我找了很多资料没有找到(官方的才可信)。 通过测试，我得到的结果是，chrome 对单页面js 内存有限制2G,对页面进程内存无限制。你一个页面进程甚至可以跑到20G。 python+Selenium 使用起来很简单，感兴趣又有需要的话，不妨一试。 附加","categories":[],"tags":[{"name":"python","slug":"python","permalink":"http://visonforcoding.xyz/tags/python/"}]},{"title":"Hello world","slug":"Hello-world","date":"2020-05-07T12:08:35.000Z","updated":"2021-06-03T06:10:31.807Z","comments":true,"path":"2020/05/07/Hello-world/","link":"","permalink":"http://visonforcoding.xyz/2020/05/07/Hello-world/","excerpt":"","text":"hello,world","categories":[],"tags":[{"name":"随笔","slug":"随笔","permalink":"http://visonforcoding.xyz/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"工欲善其事必先利其器-程序员工具","slug":"工欲善其事必先利其器","date":"2019-04-04T12:00:57.000Z","updated":"2021-06-03T06:53:26.608Z","comments":true,"path":"2019/04/04/工欲善其事必先利其器/","link":"","permalink":"http://visonforcoding.xyz/2019/04/04/%E5%B7%A5%E6%AC%B2%E5%96%84%E5%85%B6%E4%BA%8B%E5%BF%85%E5%85%88%E5%88%A9%E5%85%B6%E5%99%A8/","excerpt":"提高工作效率，首先你得有一套用的顺手的工具 图床","text":"提高工作效率，首先你得有一套用的顺手的工具 图床 PicGo 支持粘贴板，直接上传到云存储。 我用七牛云，上传之后制动把markdown的格式地址，放到粘贴板直接可以粘贴到markdown. 对喜欢用markdown写作的同学非常方便 记事本avenote 之前avenote无法写markdown，我是怎么也喜欢不上。最近发现版本更新之后可以新建markdown格式。我用重新使用上了。 boostnote 这是一款专为程序员设计的记事本，支持代码片段格式和markdown格式。 我最喜欢的一点是它的待办进度展示，很直观。 缺点就是没有云端功能和没有手机版。 rest客户端Insomnia 它最大的亮点是能支持从curl命令里新建request实例，能从chrome利的copy as curl 复制过来无缝对接。在调试接口的时候简直是完美！ git客户端gitKarken 章鱼🐙哥是我到目前为止最喜欢的git客户端，界面美观，操作设计舒服，对gitflow优雅支持。 git flow 操作很方便了。 持续更新中。。。","categories":[],"tags":[{"name":"程序人生","slug":"程序人生","permalink":"http://visonforcoding.xyz/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"}]},{"title":"docker+compose+nginx+php","slug":"docker-compose-nginx-php","date":"2018-07-22T08:52:09.000Z","updated":"2020-07-22T08:55:49.307Z","comments":true,"path":"2018/07/22/docker-compose-nginx-php/","link":"","permalink":"http://visonforcoding.xyz/2018/07/22/docker-compose-nginx-php/","excerpt":"","text":"Docker 可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。 我用docker做什么？快速搭建开发所需环境，测试实验新组件(如rabbitmq,kafka).避免因安装而浪费太多时间，我的目的是快速尝试使用。 安装dockerbrew cask install docker docker-composeCompose 是一个用户定义和运行多个容器的 Docker 应用程序。在 Compose 中你可以使用 YAML 文件来配置你的应用服务。然后，只需要一个简单的命令，就可以创建并启动你配置的所有服务。 目录结构 一组服务建立一个目录 配置文件version: &#39;2&#39; services: php7.2: image: php:7.2-fpm ports: - &quot;9000:9000&quot; volumes: - ./php:/usr/local/etc/php - /Users/caowenpeng/www:/www nginx: image: nginx ports: - &quot;80:80&quot; volumes: - /Users/caowenpeng/www:/www - ./nginx:/etc/nginx 启动docker-compose up -d 常用命令 命令 说明 up 创建和启动容器 ps 列出所有容器 down 停止并删除容器，镜像，挂载 start 启动服务 stop 停止服务 restart 重启服务 第一次使用up,之后使用start,如果再次使用up将会重新创建容器，一些对容器的修改将会丢失 其他问题进入容器 docker-compose exec php7.2 bash 进入容器后会发现只能用少量命令，连ps等都没有，这个时候需要安装一些程序 apt-get update ##更新元 apt-get install procps ## 安装 ps 安装php-rdkafka拓展 apt-get install wget wget https://github.com/edenhill/librdkafka/archive/master.zip apt-get install unzip unzip master.zip cd librdkafka ./configure make make install pecl install http://pecl.php.net/get/rdkafka-3.0.4.tgz #在php.ini 配置启用 rdkafka拓展","categories":[],"tags":[{"name":"docker","slug":"docker","permalink":"http://visonforcoding.xyz/tags/docker/"}]},{"title":"地理位置geo处理之mysql函数","slug":"地理位置geo处理之mysql函数","date":"2017-12-01T09:39:29.000Z","updated":"2021-02-25T06:56:49.777Z","comments":true,"path":"2017/12/01/地理位置geo处理之mysql函数/","link":"","permalink":"http://visonforcoding.xyz/2017/12/01/%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AEgeo%E5%A4%84%E7%90%86%E4%B9%8Bmysql%E5%87%BD%E6%95%B0/","excerpt":"目前越来越多的业务都会基于LBS，附近的人，外卖位置，附近商家等等，现就讨论离我最近这一业务场景的解决方案。 目前已知解决方案有: mysql 自定义函数计算 mysql geo索引 mongodb geo索引 postgresql PostGis索引 redis geo ElasticSearch 本文测试下mysql 函数运算的性能","text":"目前越来越多的业务都会基于LBS，附近的人，外卖位置，附近商家等等，现就讨论离我最近这一业务场景的解决方案。 目前已知解决方案有: mysql 自定义函数计算 mysql geo索引 mongodb geo索引 postgresql PostGis索引 redis geo ElasticSearch 本文测试下mysql 函数运算的性能 准备工作创建数据表CREATE TABLE `driver` ( `id` int(11) unsigned NOT NULL AUTO_INCREMENT, `lng` float DEFAULT NULL, `lat` float DEFAULT NULL, PRIMARY KEY (`id`) ) ENGINE=InnoDB DEFAULT CHARSET=utf8; 创建测试数据在创建数据之前先了解下基本的地理知识: 全球经纬度的取值范围为: 纬度-9090，经度-180180 中国的经纬度范围大约为： 纬度3.8653.55，经度73.66135.05 北京行政中心的纬度为39.92，经度为116.46 越北面的地方纬度数值越大，越东面的地方经度数值越大 度分转换： 将度分单位数据转换为度单位数据，公式：度=度+分/60 分秒转换： 将度分秒单位数据转换为度单位数据，公式：度 = 度 + 分 / 60 + 秒 / 60 / 60 在纬度相等的情况下： 经度每隔0.00001度，距离相差约1米 在经度相等的情况下： 纬度每隔0.00001度，距离相差约1.1米 mysql函数计算DELIMITER // CREATE DEFINER=`root`@`localhost` FUNCTION `getDistance`( `lng1` float(10,7) , `lat1` float(10,7) , `lng2` float(10,7) , `lat2` float(10,7) ) RETURNS double COMMENT &#39;计算2坐标点距离&#39; BEGIN declare d double; declare radius int; set radius = 6371000; #假设地球为正球形，直径为6371000米 set d = (2*ATAN2(SQRT(SIN((lat1-lat2)*PI()/180/2) *SIN((lat1-lat2)*PI()/180/2)+ COS(lat2*PI()/180)*COS(lat1*PI()/180) *SIN((lng1-lng2)*PI()/180/2) *SIN((lng1-lng2)*PI()/180/2)), SQRT(1-SIN((lat1-lat2)*PI()/180/2) *SIN((lat1-lat2)*PI()/180/2) +COS(lat2*PI()/180)*COS(lat1*PI()/180) *SIN((lng1-lng2)*PI()/180/2) *SIN((lng1-lng2)*PI()/180/2))))*radius; return d; END// DELIMITER ; 创建数据python脚本# coding=utf-8 from orator import DatabaseManager, Model import logging import random import threading &quot;&quot;&quot; 中国的经纬度范围 纬度3.86~53.55，经度73.66~135.05。大概0.00001度差距1米 &quot;&quot;&quot; # 创建 日志 对象 logger = logging.getLogger() handler = logging.StreamHandler() formatter = logging.Formatter( &#39;%(asctime)s %(name)-12s %(levelname)-8s %(message)s&#39;) handler.setFormatter(formatter) logger.addHandler(handler) logger.setLevel(logging.DEBUG) # Connect to the database config = &#123; &#39;mysql&#39;: &#123; &#39;driver&#39;: &#39;mysql&#39;, &#39;host&#39;: &#39;localhost&#39;, &#39;database&#39;: &#39;dbtest&#39;, &#39;user&#39;: &#39;root&#39;, &#39;password&#39;: &#39;&#39;, &#39;prefix&#39;: &#39;&#39; &#125; &#125; db = DatabaseManager(config) Model.set_connection_resolver(db) class Driver(Model): __table__ = &#39;driver&#39; __timestamps__ = False pass def ins_driver(thread_name,nums): logger.info(&#39;开启线程%s&#39; % thread_name) for _ in range(nums): lng = &#39;%.5f&#39; % random.uniform(73.66, 135.05) lat = &#39;%.5f&#39; % random.uniform(3.86, 53.55) driver = Driver() driver.lng = lng driver.lat = lat driver.save() thread_nums = 10 for i in range(thread_nums): t = threading.Thread(target=ins_driver, args=(i, 400000)) t.start() 以上脚本创建10个线程，10个线程插入4万条数据。耗费150.18s执行完,总共插入40万条数据 测试 测试环境 系统：mac os 内存：16G cpu: intel core i5 硬盘: 500g 固态硬盘 测试下查找距离(134.38753,18.56734)这个坐标点最近的10个司机 select *,`getDistance`(134.38753,18.56734,`lng`,`lat`) as dis from driver ORDER BY dis limit 10 耗时：18.0s explain:全表扫描 我测试了从1万到10万间隔1万和从10万到90万每间隔10万测试的结果变化 结论 此方案在数据量达到3万条查询耗时就会超过1秒 大约每增加1万条就会增加0.4秒的耗时","categories":[],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://visonforcoding.xyz/tags/mysql/"}]},{"title":"地理位置geo处理之mongodb geo 索引","slug":"地理位置处理之mongodb","date":"2017-12-01T02:34:00.000Z","updated":"2020-05-09T02:46:03.742Z","comments":true,"path":"2017/12/01/地理位置处理之mongodb/","link":"","permalink":"http://visonforcoding.xyz/2017/12/01/%E5%9C%B0%E7%90%86%E4%BD%8D%E7%BD%AE%E5%A4%84%E7%90%86%E4%B9%8Bmongodb/","excerpt":"目前越来越多的业务都会基于LBS，附近的人，外卖位置，附近商家等等，现就讨论离我最近这一业务场景的解决方案。 目前已知解决方案有: mysql 自定义函数计算 mysql geo索引 mongodb geo索引 postgresql PostGis索引 redis geo ElasticSearch 本文测试下mongodb geo索引 函数运算的性能","text":"目前越来越多的业务都会基于LBS，附近的人，外卖位置，附近商家等等，现就讨论离我最近这一业务场景的解决方案。 目前已知解决方案有: mysql 自定义函数计算 mysql geo索引 mongodb geo索引 postgresql PostGis索引 redis geo ElasticSearch 本文测试下mongodb geo索引 函数运算的性能 准备工作创建数据表db.driver.createIndex(&#123;loc: &quot;2dsphere&quot;&#125;) 创建数据python脚本# coding=utf-8 from pymongo import MongoClient import logging import random import threading &quot;&quot;&quot; 中国的经纬度范围 纬度3.86~53.55，经度73.66~135.05。大概0.00001度差距1米 &quot;&quot;&quot; # 创建 日志 对象 logger = logging.getLogger() handler = logging.StreamHandler() formatter = logging.Formatter( &#39;%(asctime)s %(name)-12s %(levelname)-8s %(message)s&#39;) handler.setFormatter(formatter) logger.addHandler(handler) logger.setLevel(logging.DEBUG) # Connect to the mongodb database mongoconn = MongoClient(&#39;127.0.0.1&#39;, 27017) mdb = mongoconn.geo_analysis driver_collection = mdb.driver def ins_driver(thread_name, nums): logger.info(&#39;开启线程%s&#39; % thread_name) for i in range(nums): lng = &#39;%.5f&#39; % random.uniform(73.66, 135.05) lat = &#39;%.5f&#39; % random.uniform(3.86, 53.55) logging.debug(&#39;插入记录:%s&#39; % i) driver_collection.insert_one(&#123; &quot;loc&quot;:[ float(lng), float(lat) ] &#125;) thread_nums = 10 for i in range(thread_nums): t = threading.Thread(target=ins_driver, args=(i, 40000)) t.start() 以上脚本创建10个线程，10个线程插入4万条数据。耗费52.43s执行完,总共插入40万条数据 测试 测试环境 系统：mac os 内存：16G cpu: intel core i5 硬盘: 500g 固态硬盘 测试下查找距离(134.38753,18.56734)附近20公里的司机 db.runCommand(&#123;geoNear:&#39;driver&#39;, near:[134.38753,18.56734], spherical:true, maxDistance:20000/6378000, distanceMultiplier:6378000&#125;); 耗时：0.001s explain:使用索引","categories":[],"tags":[{"name":"方案","slug":"方案","permalink":"http://visonforcoding.xyz/tags/%E6%96%B9%E6%A1%88/"}]},{"title":"程序员代码下的许豪杰(技术篇)","slug":"python/程序员代码下的许豪杰-技术篇","date":"2017-08-05T05:16:00.000Z","updated":"2020-09-23T09:12:52.825Z","comments":true,"path":"2017/08/05/python/程序员代码下的许豪杰-技术篇/","link":"","permalink":"http://visonforcoding.xyz/2017/08/05/python/%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BB%A3%E7%A0%81%E4%B8%8B%E7%9A%84%E8%AE%B8%E8%B1%AA%E6%9D%B0-%E6%8A%80%E6%9C%AF%E7%AF%87/","excerpt":"接上篇，这一篇将从技术层面讲讲是如何实现的。阅读本文您将会了解如何用python爬取微博的评论以及如何用python word_cloud库进行数据可视化。 上一篇:程序员代码下的许豪杰","text":"接上篇，这一篇将从技术层面讲讲是如何实现的。阅读本文您将会了解如何用python爬取微博的评论以及如何用python word_cloud库进行数据可视化。 上一篇:程序员代码下的许豪杰 准备工作打开微博pc m站并找到许豪杰该条微博地址:https://m.weibo.cn/status/4132385564040383 为什么要用m站地址？因为m站可以直接抓取到api json数据,而pc站虽然也有api返回的是html,相比而言选取m站会省去很多麻烦 打开该页面，并且用chrome 的检查工具 查看network，可以获取到评论的api地址。 数据抓取首先观察api返回 从返回地址上可以看到可以通过参数page 改变请求的页码,并且每页都回返回总条数和总页码数。这里我决定采用多线程来抓去(其实数据量不大,也可以单线程跑)。 其中在爬取数据的时候会面临几个问题：1.存储选择 我这里选用了MongoDB作为数据存储，因为api通常返回的是json数据而json结构和MongoDB的存储方式可以结合的很默契，不需要经过任何处理可以直接的进行插入。 2.防爬虫 很多网站可能会做一些防爬虫的处理，面对同一个请求ip的短时间的高频率请求会进行服务隔断(直接告诉你服务不可用)，这个时候可以去网上找一些代理进行请求。 3.多线程的任务分配 采用多线程爬取你当然不能让多个线程去爬取同样的链接做别人已经做过的事情，那样多线程毫无意义。所以你需要制定一套规则，让不同线程爬取不同的链接。 # coding=utf-8 from __future__ import division from pymongo import MongoClient import requests import sys import re import random import time import logging import threading import json from os import path import math # 爬取微博评论 # m站微博地址 weibo_url = &#39;https://m.weibo.cn/status/4132385564040383&#39; thread_nums = 5 #线程数 #代理地址 proxies = &#123; &quot;http&quot;: &quot;http://171.92.4.67:9000&quot;, &quot;http&quot;: &quot;http://163.125.222.240:8118&quot;, &quot;http&quot;: &quot;http://121.232.145.251:9000&quot;, &quot;http&quot;: &quot;http://121.232.147.247:9000&quot;, &#125; # 创建 日志 对象 logger = logging.getLogger() handler = logging.StreamHandler() formatter = logging.Formatter( &#39;%(asctime)s %(name)-12s %(levelname)-8s %(message)s&#39;) handler.setFormatter(formatter) logger.addHandler(handler) logger.setLevel(logging.DEBUG) mongoconn = MongoClient(&#39;127.0.0.1&#39;, 27017) mdb = mongoconn.data_analysis das_collection = mdb.weibo weiboid_reobj = re.match(r&#39;.*status/(\\d+)&#39;, weibo_url) weibo_id = weiboid_reobj.group(1) def scrapy_comments(weibo_id, page): weibo_comment_url = &#39;https://m.weibo.cn/api/comments/show?id=%s&amp;page=%d&#39; % ( weibo_id, page) res = requests.get(weibo_comment_url) res_obj = json.loads(res.content) return res_obj def import_comments(threadName, weibo_id, page_start, page_end): logger.info(&#39;开始线程:%s&#39; % threadName) for page in range(page_start, page_end + 1): logging.info(&#39;读取第%s页&#39; % page) time.sleep(1) # continue try: res_obj = scrapy_comments(weibo_id, page) logging.info(&#39;该页有%s条记录&#39; % len(res_obj[&#39;data&#39;])) except: logging.error(&#39;读取%s页时发生错误&#39; % page) continue if res_obj[&#39;ok&#39;] == 1: comments = res_obj[&#39;data&#39;] for comment in comments: comment_text = re.sub( r&#39;&lt;/?\\w+[^&gt;]*&gt;&#39;, &#39;&#39;, comment[&#39;text&#39;]).encode(&#39;utf-8&#39;) if re.search(r&#39;回复@.*:&#39;, comment_text): # 过滤掉回复别人的评论 continue comment[&#39;text&#39;] = comment_text comment[&#39;weibo_id&#39;] = weibo_id logging.info(&#39;读取评论:%s&#39; % comment[&#39;id&#39;]) try: if das_collection.find_one(&#123;&#39;id&#39;: comment[&#39;id&#39;]&#125;): logging.info(&#39;在mongodb中存在&#39;) else: logging.info(&#39;插入记录:%s&#39; % comment[&#39;id&#39;]) das_collection.insert_one(comment) except: logging.error(&#39;mongodb发生错误&#39;) else: logging.error(&#39;读取第%s页时发生错误&#39; % page) logging.info(&#39;线程%s结束&#39; % threadName) # res_obj = scrapy_comments(weibo_id, page) if __name__ == &#39;__main__&#39;: # 分配不同链接到不同的线程上去 res_obj = scrapy_comments(weibo_id, 1) if res_obj[&#39;ok&#39;] == 1: total_number = res_obj[&#39;total_number&#39;] logging.info(&#39;该条微博有:%s条评论&#39; % total_number) max_page = res_obj[&#39;max&#39;] page_nums = math.ceil(max_page / thread_nums) else: raise # print max_page # print page_nums for i in range(1, thread_nums + 1): if i &lt; thread_nums: page_end = page_nums * i else: page_end = max_page page_start = (i - 1) * page_nums + 1 t = threading.Thread(target=import_comments, args=( i, weibo_id, int(page_start), int(page_end))) t.start() 数据整理可视化(data visualization)运行脚本完毕，我的MongoDB得到了2万多条评论数据，接下来要做的事是对这部分数据进行提取、清洗、结构化等操作。这里顺便说明一下python 数据分析的 大致基本流程。 1.与外界进行交互这个过程包括数据的获取、读取。不管是从网络资源上爬取、还是从现有资源(各样的文件如文本、excel、数据库存储对象) 2.准备工作对数据进行清洗(cleaning)、修整(munging)、整合(combining)、规范化(normalizing)、重塑(reshaping)、切片(slicing)和切块(dicing) 3.转换对数据集做一些数学和统计运算产生新的数据集 4.建模和计算将数据跟统计模型、机器学习算法或其他计算工具联系起来 5.展示创建交互式的或静态的图片或文字摘要 下面我们来进行2、3及5的工作: # coding=utf-8 import sys from pymongo import MongoClient import random # 分词库 # from snownlp import SnowNLP import jieba import uniout from collections import Counter, OrderedDict # 词语云 文本统计可视化库 from wordcloud import WordCloud mongoconn = MongoClient(&#39;127.0.0.1&#39;, 27017) mdb = mongoconn.data_analysis das_collection = mdb.weibo total_counts = das_collection.find().count() # random_int = random.randint(0, total_counts - 1) docs = das_collection.find() print docs.count() words_counts = &#123;&#125; for doc in docs: print doc comment_text = doc[&#39;text&#39;].encode(&#39;utf-8&#39;) if len(comment_text) == 0: continue words = jieba.cut(comment_text) for word in words: if word not in words_counts: words_counts[word] = 1 else: words_counts[word] += 1 for word in words_counts.keys(): if words_counts[word] &lt; 2 or len(word) &lt; 2: del words_counts[word] # print words_counts.items() #注意要让中文不乱码要指定中文字体 #fit_words 接收参数是dict eg:&#123;&#39;你&#39;:333,&#39;好&#39;:23&#125; 文字:出现次数 wordcloud = WordCloud( font_path=&#39;/Users/cwp/font/msyh.ttf&#39;, background_color=&#39;white&#39;, width=1200, height=1000 ).fit_words(words_counts) import matplotlib.pyplot as plt plt.imshow(wordcloud, interpolation=&#39;bilinear&#39;) plt.axis(&quot;off&quot;) plt.show() 介绍下以上代码：我们主要用到了2个工具，jieba和word_cloud。前者对中文进行分词后者图形化展示词语的出现频率。众所周知，中文系的语言处理恐怕是最难的自然语言处理(NLP)的语种。就基本的分词而言都是一项比较困难的工作,(英语句子中每个单词都是有空格分开的，而中文是由单个字组成词连接成串组成句).举个例子,请用“孩提”造句,”那个男孩提交完代码就下班了”。如果人工分词，可以知道”男孩”和”提交”应该是分开的2个词，但是对于机器而言，要辨别”提”应该与”男”还是”交”进行组词就很难办了。要想机器能够更精确的辨别这类问题，就需要让机器不停学习，让它知道这种情况该这么分而不是那么分。研究中文自然语言处理将是一个长久而大的工程，对于分析数据(我们不是要研究自然语言处理😏)，这里就借助jieba这个库进行工作了. 对于word_cloud,图形化文本统计，网上有不少的博文都贴了代码，但我想说的是我不了解它们是不是真的运行出了结果。因为fit_words 这个函数接收的是dict而不是list，官方文档和函数doc其实写错了,在github上有披露。 最后得到结果: 一些用到的工具1.word_cloud A little word cloud generator in Python 2.jieba 结巴中文分词 3.Requests is the only Non-GMO HTTP library for Python, safe for human consumption.","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"管理","slug":"管理","permalink":"http://visonforcoding.xyz/tags/%E7%AE%A1%E7%90%86/"},{"name":"技术工程","slug":"技术工程","permalink":"http://visonforcoding.xyz/tags/%E6%8A%80%E6%9C%AF%E5%B7%A5%E7%A8%8B/"},{"name":"PHP","slug":"PHP","permalink":"http://visonforcoding.xyz/tags/PHP/"},{"name":"php","slug":"php","permalink":"http://visonforcoding.xyz/tags/php/"},{"name":"架构","slug":"架构","permalink":"http://visonforcoding.xyz/tags/%E6%9E%B6%E6%9E%84/"},{"name":"mysql","slug":"mysql","permalink":"http://visonforcoding.xyz/tags/mysql/"},{"name":"web","slug":"web","permalink":"http://visonforcoding.xyz/tags/web/"},{"name":"java","slug":"java","permalink":"http://visonforcoding.xyz/tags/java/"},{"name":"软件工程","slug":"软件工程","permalink":"http://visonforcoding.xyz/tags/%E8%BD%AF%E4%BB%B6%E5%B7%A5%E7%A8%8B/"},{"name":"JAVA","slug":"JAVA","permalink":"http://visonforcoding.xyz/tags/JAVA/"},{"name":"Java","slug":"Java","permalink":"http://visonforcoding.xyz/tags/Java/"},{"name":"spring-boot","slug":"spring-boot","permalink":"http://visonforcoding.xyz/tags/spring-boot/"},{"name":"运维","slug":"运维","permalink":"http://visonforcoding.xyz/tags/%E8%BF%90%E7%BB%B4/"},{"name":"devops","slug":"devops","permalink":"http://visonforcoding.xyz/tags/devops/"},{"name":"web前端","slug":"web前端","permalink":"http://visonforcoding.xyz/tags/web%E5%89%8D%E7%AB%AF/"},{"name":"python","slug":"python","permalink":"http://visonforcoding.xyz/tags/python/"},{"name":"kafka","slug":"kafka","permalink":"http://visonforcoding.xyz/tags/kafka/"},{"name":"php linux","slug":"php-linux","permalink":"http://visonforcoding.xyz/tags/php-linux/"},{"name":"java spring-boot","slug":"java-spring-boot","permalink":"http://visonforcoding.xyz/tags/java-spring-boot/"},{"name":"随笔","slug":"随笔","permalink":"http://visonforcoding.xyz/tags/%E9%9A%8F%E7%AC%94/"},{"name":"程序人生","slug":"程序人生","permalink":"http://visonforcoding.xyz/tags/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/"},{"name":"docker","slug":"docker","permalink":"http://visonforcoding.xyz/tags/docker/"},{"name":"方案","slug":"方案","permalink":"http://visonforcoding.xyz/tags/%E6%96%B9%E6%A1%88/"}]}